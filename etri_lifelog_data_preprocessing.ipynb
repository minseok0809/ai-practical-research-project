{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ETRI Lifelog Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Devleopment Envrionment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tqdm\n",
    "import glob\n",
    "import pyarrow\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from termcolor import colored\n",
    "from functools import reduce\n",
    "from dateutil import parser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.0 Train Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0.1 Train Label Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>date</th>\n",
       "      <th>Q1</th>\n",
       "      <th>Q2</th>\n",
       "      <th>Q3</th>\n",
       "      <th>S1</th>\n",
       "      <th>S2</th>\n",
       "      <th>S3</th>\n",
       "      <th>S4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>user01</td>\n",
       "      <td>2020-08-30</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>user01</td>\n",
       "      <td>2020-08-31</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>506</th>\n",
       "      <td>user30</td>\n",
       "      <td>2020-09-24</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>507</th>\n",
       "      <td>user30</td>\n",
       "      <td>2020-09-25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>508 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     userId        date  Q1  Q2  Q3  S1  S2  S3  S4\n",
       "0    user01  2020-08-30   1   0   0   1   1   0   0\n",
       "1    user01  2020-08-31   0   0   0   0   1   1   1\n",
       "..      ...         ...  ..  ..  ..  ..  ..  ..  ..\n",
       "506  user30  2020-09-24   1   0   1   0   1   1   1\n",
       "507  user30  2020-09-25   0   0   1   0   1   1   0\n",
       "\n",
       "[508 rows x 9 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "path = '/workspace/human_understanding_2024/train_label.csv'\n",
    "train_label_df = pd.read_csv(path)\n",
    "train_label_df = train_label_df.sort_values(\"subject_id\")\n",
    "train_users = sorted(list(set(list(train_label_df['subject_id']))))\n",
    "user_label_dfs = []\n",
    "for idx, train_user in enumerate(train_users):\n",
    "    user_label = train_label_df['subject_id'] == train_user   \n",
    "    user_label_df = train_label_df[user_label]\n",
    "    del user_label_df['Unnamed: 0']\n",
    "    user_label_df = user_label_df.sort_values(\"date\").reset_index(drop=True)\n",
    "    user_label_df.columns = ['userId', 'date', 'Q1', 'Q2', 'Q3', 'S1', 'S2', 'S3', 'S4']\n",
    "    user_label_dfs.append(user_label_df)\n",
    "    \n",
    "    if idx == 0:\n",
    "        pd.set_option('display.max_rows', 4)\n",
    "        pd.set_option('display.max_colwidth', None)\n",
    "        # display(user_label_df)\n",
    "        # print()\n",
    "\n",
    "pd.set_option('display.max_rows', 4)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "all_user_label_df = pd.concat(user_label_dfs, axis=0).reset_index(drop=True)\n",
    "display(all_user_label_df)          "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0.2 Train Sleep Time Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mSleep Time\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>date</th>\n",
       "      <th>startDt</th>\n",
       "      <th>endDt</th>\n",
       "      <th>lastUpdate</th>\n",
       "      <th>startPosition</th>\n",
       "      <th>endPosition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>user01</td>\n",
       "      <td>2020-08-31</td>\n",
       "      <td>1598802240</td>\n",
       "      <td>1598830980</td>\n",
       "      <td>1598838373</td>\n",
       "      <td>1598802240</td>\n",
       "      <td>1598838373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>user01</td>\n",
       "      <td>2020-09-01</td>\n",
       "      <td>1598897280</td>\n",
       "      <td>1598922060</td>\n",
       "      <td>1598923633</td>\n",
       "      <td>1598838373</td>\n",
       "      <td>1598923633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>613</th>\n",
       "      <td>user30</td>\n",
       "      <td>2020-09-25</td>\n",
       "      <td>1600965120</td>\n",
       "      <td>1600987200</td>\n",
       "      <td>1600987323</td>\n",
       "      <td>1600900872</td>\n",
       "      <td>1600987323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>614</th>\n",
       "      <td>user30</td>\n",
       "      <td>2020-09-26</td>\n",
       "      <td>1601058000</td>\n",
       "      <td>1601079120</td>\n",
       "      <td>1601086511</td>\n",
       "      <td>1600987323</td>\n",
       "      <td>1601086511</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>615 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     userId        date     startDt       endDt  lastUpdate  startPosition  \\\n",
       "0    user01  2020-08-31  1598802240  1598830980  1598838373     1598802240   \n",
       "1    user01  2020-09-01  1598897280  1598922060  1598923633     1598838373   \n",
       "..      ...         ...         ...         ...         ...            ...   \n",
       "613  user30  2020-09-25  1600965120  1600987200  1600987323     1600900872   \n",
       "614  user30  2020-09-26  1601058000  1601079120  1601086511     1600987323   \n",
       "\n",
       "     endPosition  \n",
       "0     1598838373  \n",
       "1     1598923633  \n",
       "..           ...  \n",
       "613   1600987323  \n",
       "614   1601086511  \n",
       "\n",
       "[615 rows x 7 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "path = '/workspace/human_understanding_2025/user_sleep_2020.csv'\n",
    "user_sleep_df = pd.read_csv(path)\n",
    "user_sleep_df = user_sleep_df[['userId', 'date', 'startDt', 'endDt', 'lastUpdate']]  \n",
    "train_sleep_users = sorted(list(set(list(user_sleep_df['userId']))))\n",
    "user_Dt_dfs = []\n",
    "for idx, train_sleep_user in enumerate(train_sleep_users):\n",
    "    user_Dt = user_sleep_df['userId'] == train_sleep_user   \n",
    "    user_Dt_df = user_sleep_df[user_Dt]\n",
    "    user_Dt_df = user_Dt_df.sort_values(\"date\").reset_index(drop=True)\n",
    "    user_Dt_df['startPosition'] = list(user_Dt_df['startDt'])[0:1] + list(user_Dt_df['lastUpdate'])[:-1]\n",
    "    user_Dt_df['endPosition'] = list(user_Dt_df['lastUpdate'])\n",
    "    user_Dt_dfs.append(user_Dt_df)\n",
    "    \n",
    "    if idx == 0:\n",
    "        pd.set_option('display.max_rows', 4)\n",
    "        pd.set_option('display.max_colwidth', None)\n",
    "        # display(user_Dt_df)  \n",
    "        # print()\n",
    "        \n",
    "print(colored(\"Sleep Time\", attrs=['bold']))\n",
    "pd.set_option('display.max_rows', 4)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "all_user_Dt_df = pd.concat(user_Dt_dfs, axis=0).reset_index(drop=True)   \n",
    "display(all_user_Dt_df)             "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0.3 Time, Feature Dataframe from Folder Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mTime from Folder Name\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>Dt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>user01</td>\n",
       "      <td>1598759880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>user01</td>\n",
       "      <td>1598832660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>569</th>\n",
       "      <td>user30</td>\n",
       "      <td>1601079300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>570</th>\n",
       "      <td>user30</td>\n",
       "      <td>1601165700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>571 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     userId          Dt\n",
       "0    user01  1598759880\n",
       "1    user01  1598832660\n",
       "..      ...         ...\n",
       "569  user30  1601079300\n",
       "570  user30  1601165700\n",
       "\n",
       "[571 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1mFeature from Folder Name\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>Dt</th>\n",
       "      <th>missing feature</th>\n",
       "      <th>feature</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>user01</td>\n",
       "      <td>1598759880</td>\n",
       "      <td>[e4Bvp, e4Acc, e4Eda, e4Hr, e4Temp]</td>\n",
       "      <td>{'mGps': 463, 'mAcc': 437, 'e4Bvp': 0, 'e4Acc': 0, 'mGyr': 405, 'mMag': 433, 'e4Eda': 0, 'e4Hr': 0, 'e4Temp': 0}</td>\n",
       "      <td>/workspace/human_understanding_2025/user01-06/user01/1598759880/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>user01</td>\n",
       "      <td>1598832660</td>\n",
       "      <td>all right</td>\n",
       "      <td>{'mGps': 778, 'mAcc': 728, 'e4Bvp': 119, 'e4Acc': 119, 'mGyr': 723, 'mMag': 723, 'e4Eda': 119, 'e4Hr': 119, 'e4Temp': 119}</td>\n",
       "      <td>/workspace/human_understanding_2025/user01-06/user01/1598832660/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>569</th>\n",
       "      <td>user30</td>\n",
       "      <td>1601079300</td>\n",
       "      <td>all right</td>\n",
       "      <td>{'mGps': 772, 'mAcc': 772, 'e4Bvp': 770, 'e4Acc': 770, 'mGyr': 772, 'mMag': 772, 'e4Eda': 770, 'e4Hr': 770, 'e4Temp': 770}</td>\n",
       "      <td>/workspace/human_understanding_2025/user26-30/user30/1601079300/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>570</th>\n",
       "      <td>user30</td>\n",
       "      <td>1601165700</td>\n",
       "      <td>all right</td>\n",
       "      <td>{'mGps': 753, 'mAcc': 755, 'e4Bvp': 742, 'e4Acc': 742, 'mGyr': 755, 'mMag': 755, 'e4Eda': 742, 'e4Hr': 742, 'e4Temp': 580}</td>\n",
       "      <td>/workspace/human_understanding_2025/user26-30/user30/1601165700/</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>571 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     userId          Dt                      missing feature  \\\n",
       "0    user01  1598759880  [e4Bvp, e4Acc, e4Eda, e4Hr, e4Temp]   \n",
       "1    user01  1598832660                            all right   \n",
       "..      ...         ...                                  ...   \n",
       "569  user30  1601079300                            all right   \n",
       "570  user30  1601165700                            all right   \n",
       "\n",
       "                                                                                                                        feature  \\\n",
       "0              {'mGps': 463, 'mAcc': 437, 'e4Bvp': 0, 'e4Acc': 0, 'mGyr': 405, 'mMag': 433, 'e4Eda': 0, 'e4Hr': 0, 'e4Temp': 0}   \n",
       "1    {'mGps': 778, 'mAcc': 728, 'e4Bvp': 119, 'e4Acc': 119, 'mGyr': 723, 'mMag': 723, 'e4Eda': 119, 'e4Hr': 119, 'e4Temp': 119}   \n",
       "..                                                                                                                          ...   \n",
       "569  {'mGps': 772, 'mAcc': 772, 'e4Bvp': 770, 'e4Acc': 770, 'mGyr': 772, 'mMag': 772, 'e4Eda': 770, 'e4Hr': 770, 'e4Temp': 770}   \n",
       "570  {'mGps': 753, 'mAcc': 755, 'e4Bvp': 742, 'e4Acc': 742, 'mGyr': 755, 'mMag': 755, 'e4Eda': 742, 'e4Hr': 742, 'e4Temp': 580}   \n",
       "\n",
       "                                                                 path  \n",
       "0    /workspace/human_understanding_2025/user01-06/user01/1598759880/  \n",
       "1    /workspace/human_understanding_2025/user01-06/user01/1598832660/  \n",
       "..                                                                ...  \n",
       "569  /workspace/human_understanding_2025/user26-30/user30/1601079300/  \n",
       "570  /workspace/human_understanding_2025/user26-30/user30/1601165700/  \n",
       "\n",
       "[571 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1mMissing Feature from Folder Name\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>Dt</th>\n",
       "      <th>missing feature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>user01</td>\n",
       "      <td>1598759880</td>\n",
       "      <td>[e4Bvp, e4Acc, e4Eda, e4Hr, e4Temp]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>user01</td>\n",
       "      <td>1600873320</td>\n",
       "      <td>[mGps, e4Eda]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>user28</td>\n",
       "      <td>1600117200</td>\n",
       "      <td>[e4Bvp, e4Acc, e4Eda, e4Hr, e4Temp]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>user29</td>\n",
       "      <td>1598762940</td>\n",
       "      <td>[e4Bvp, e4Acc, e4Eda, e4Hr, e4Temp]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>97 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    userId          Dt                      missing feature\n",
       "0   user01  1598759880  [e4Bvp, e4Acc, e4Eda, e4Hr, e4Temp]\n",
       "1   user01  1600873320                        [mGps, e4Eda]\n",
       "..     ...         ...                                  ...\n",
       "95  user28  1600117200  [e4Bvp, e4Acc, e4Eda, e4Hr, e4Temp]\n",
       "96  user29  1598762940  [e4Bvp, e4Acc, e4Eda, e4Hr, e4Temp]\n",
       "\n",
       "[97 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "user_ids = []; user_Dts =[]; user_features =[]; user_missing_features = []\n",
    "components = []\n",
    "\n",
    "directory = ['user01-06/', 'user07-10/', \n",
    "             'user11-12/', 'user21-25/', 'user26-30/']\n",
    "\n",
    "for dir in directory:\n",
    "    p = \"/workspace/human_understanding_2025/\" + dir\n",
    "    user_list = glob.glob(p + \"*\" + os.path.sep)\n",
    "    for user in user_list:\n",
    "        component_list = glob.glob(user + \"*\" + os.path.sep)\n",
    "\n",
    "        for component in component_list:\n",
    "            user_name = component.split(\"/\")[-3]\n",
    "            Dt = component.split(\"/\")[-2]\n",
    "            \n",
    "            user_ids.append(user_name)\n",
    "            user_Dts.append(Dt)\n",
    "            \n",
    "            feature_list = glob.glob(component + \"*\" + os.path.sep)\n",
    "            \n",
    "            user_feature = {}; user_missing_feature = []\n",
    "            for feature in feature_list:\n",
    "                feature_name = feature.split(\"/\")[-2]\n",
    "                csv_list = glob.glob(feature + \"*.csv\")\n",
    "                csv_num = len(csv_list)\n",
    "                user_feature[feature_name] = csv_num\n",
    "\n",
    "                if csv_num == 0:\n",
    "                    user_missing_feature.append(feature_name)\n",
    "\n",
    "            user_features.append(user_feature)\n",
    "            components.append(component)\n",
    "\n",
    "            if len(user_missing_feature) == 0:\n",
    "                user_missing_feature = \"all right\"\n",
    "            user_missing_features.append(user_missing_feature)\n",
    "\n",
    "user_folder_df = pd.DataFrame({\"userId\":user_ids,\n",
    "                              \"Dt\":user_Dts})\n",
    "user_folder_df = user_folder_df.sort_values(\"userId\")\n",
    "\n",
    "user_feature_df = pd.DataFrame({\"userId\":user_ids,\n",
    "                              \"Dt\":user_Dts,\n",
    "                              \"missing feature\":user_missing_features,\n",
    "                              \"feature\":user_features,\n",
    "                              \"path\":components})\n",
    "user_feature_df = user_feature_df.sort_values(\"userId\")\n",
    "\n",
    "user_folder_dfs = []; user_feature_dfs = []\n",
    "train_startDt_users = sorted(list(set(list(user_ids))))\n",
    "for idx, train_startDt_user in enumerate(train_startDt_users):\n",
    "    user_folder = user_folder_df['userId'] == train_startDt_user   \n",
    "    folder_user_df = user_folder_df[user_folder]\n",
    "    folder_user_df = folder_user_df.sort_values(\"Dt\").reset_index(drop=True)\n",
    "    user_folder_dfs.append(folder_user_df)\n",
    "\n",
    "    user_feature = user_feature_df['userId'] == train_startDt_user   \n",
    "    feature_user_df = user_feature_df[user_feature]\n",
    "    feature_user_df = feature_user_df.sort_values(\"Dt\").reset_index(drop=True)\n",
    "    user_feature_dfs.append(feature_user_df)\n",
    "    \n",
    "    if idx == 0:\n",
    "        pd.set_option('display.max_rows', 4)\n",
    "        pd.set_option('display.max_colwidth', None)\n",
    "        \n",
    "        # print(colored(\"Time from Folder Name\", attrs=['bold']))\n",
    "        # display(folder_user_df)  \n",
    "        # print()\n",
    "\n",
    "        # print(colored(\"Feature from Folder Name\", attrs=['bold']))\n",
    "        # display(feature_user_df)\n",
    "        # print()\n",
    "\n",
    "print(colored(\"Time from Folder Name\", attrs=['bold']))\n",
    "all_user_folder_df = pd.concat(user_folder_dfs, axis=0).reset_index(drop=True)   \n",
    "pd.set_option('display.max_rows', 4)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "display(all_user_folder_df)   \n",
    "print()\n",
    "\n",
    "print(colored(\"Feature from Folder Name\", attrs=['bold']))\n",
    "all_user_feature_df = pd.concat(user_feature_dfs, axis=0).reset_index(drop=True)   \n",
    "pd.set_option('display.max_rows', 4)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "display(all_user_feature_df) \n",
    "print()\n",
    "\n",
    "user_ids = []; user_Dts = []; user_missing_features = []\n",
    "for user_feature_df in user_feature_dfs:\n",
    "    for idx, row in user_feature_df.iterrows():\n",
    "        if row['missing feature'] != \"all right\":\n",
    "            user_ids.append(row['userId'])\n",
    "            user_Dts.append(row['Dt'])\n",
    "            user_missing_features.append(row['missing feature'])\n",
    "\n",
    "all_user_missing_feature_df = pd.DataFrame({\"userId\":user_ids,\n",
    "                            \"Dt\":user_Dts,\n",
    "                            \"missing feature\":user_missing_features}) \n",
    "\n",
    "print(colored(\"Missing Feature from Folder Name\", attrs=['bold']))\n",
    "pd.set_option('display.max_rows', 4)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "display(all_user_missing_feature_df)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0.4 Matched Train Input CSV Path Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mMatched Folder\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>date</th>\n",
       "      <th>Dt</th>\n",
       "      <th>startPosition</th>\n",
       "      <th>endPosition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>user01</td>\n",
       "      <td>2020-08-31</td>\n",
       "      <td>1598832660</td>\n",
       "      <td>1598802240</td>\n",
       "      <td>1598838373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>user01</td>\n",
       "      <td>2020-09-05</td>\n",
       "      <td>1599269580</td>\n",
       "      <td>1599185829</td>\n",
       "      <td>1599273253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>user30</td>\n",
       "      <td>2020-09-24</td>\n",
       "      <td>1600816380</td>\n",
       "      <td>1600814550</td>\n",
       "      <td>1600896726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>user30</td>\n",
       "      <td>2020-09-25</td>\n",
       "      <td>1600902660</td>\n",
       "      <td>1600900872</td>\n",
       "      <td>1600987323</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>468 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     userId        date          Dt  startPosition  endPosition\n",
       "0    user01  2020-08-31  1598832660     1598802240   1598838373\n",
       "1    user01  2020-09-05  1599269580     1599185829   1599273253\n",
       "..      ...         ...         ...            ...          ...\n",
       "466  user30  2020-09-24  1600816380     1600814550   1600896726\n",
       "467  user30  2020-09-25  1600902660     1600900872   1600987323\n",
       "\n",
       "[468 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1mTrain Input Information\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>date</th>\n",
       "      <th>Dt</th>\n",
       "      <th>startPosition</th>\n",
       "      <th>endPosition</th>\n",
       "      <th>missing feature</th>\n",
       "      <th>feature</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>user01</td>\n",
       "      <td>2020-08-31</td>\n",
       "      <td>1598832660</td>\n",
       "      <td>1598802240</td>\n",
       "      <td>1598838373</td>\n",
       "      <td>all right</td>\n",
       "      <td>{'mGps': 778, 'mAcc': 728, 'e4Bvp': 119, 'e4Acc': 119, 'mGyr': 723, 'mMag': 723, 'e4Eda': 119, 'e4Hr': 119, 'e4Temp': 119}</td>\n",
       "      <td>/workspace/human_understanding_2025/user01-06/user01/1598832660/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>user01</td>\n",
       "      <td>2020-09-05</td>\n",
       "      <td>1599269580</td>\n",
       "      <td>1599185829</td>\n",
       "      <td>1599273253</td>\n",
       "      <td>all right</td>\n",
       "      <td>{'mGps': 698, 'mAcc': 677, 'e4Bvp': 689, 'e4Acc': 689, 'mGyr': 642, 'mMag': 642, 'e4Eda': 689, 'e4Hr': 688, 'e4Temp': 689}</td>\n",
       "      <td>/workspace/human_understanding_2025/user01-06/user01/1599269580/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>user30</td>\n",
       "      <td>2020-09-24</td>\n",
       "      <td>1600816380</td>\n",
       "      <td>1600814550</td>\n",
       "      <td>1600896726</td>\n",
       "      <td>all right</td>\n",
       "      <td>{'mGps': 840, 'mAcc': 841, 'e4Bvp': 829, 'e4Acc': 829, 'mGyr': 841, 'mMag': 841, 'e4Eda': 829, 'e4Hr': 828, 'e4Temp': 829}</td>\n",
       "      <td>/workspace/human_understanding_2025/user26-30/user30/1600816380/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>user30</td>\n",
       "      <td>2020-09-25</td>\n",
       "      <td>1600902660</td>\n",
       "      <td>1600900872</td>\n",
       "      <td>1600987323</td>\n",
       "      <td>all right</td>\n",
       "      <td>{'mGps': 753, 'mAcc': 740, 'e4Bvp': 743, 'e4Acc': 743, 'mGyr': 725, 'mMag': 754, 'e4Eda': 743, 'e4Hr': 743, 'e4Temp': 743}</td>\n",
       "      <td>/workspace/human_understanding_2025/user26-30/user30/1600902660/</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>468 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     userId        date          Dt  startPosition  endPosition  \\\n",
       "0    user01  2020-08-31  1598832660     1598802240   1598838373   \n",
       "1    user01  2020-09-05  1599269580     1599185829   1599273253   \n",
       "..      ...         ...         ...            ...          ...   \n",
       "466  user30  2020-09-24  1600816380     1600814550   1600896726   \n",
       "467  user30  2020-09-25  1600902660     1600900872   1600987323   \n",
       "\n",
       "    missing feature  \\\n",
       "0         all right   \n",
       "1         all right   \n",
       "..              ...   \n",
       "466       all right   \n",
       "467       all right   \n",
       "\n",
       "                                                                                                                        feature  \\\n",
       "0    {'mGps': 778, 'mAcc': 728, 'e4Bvp': 119, 'e4Acc': 119, 'mGyr': 723, 'mMag': 723, 'e4Eda': 119, 'e4Hr': 119, 'e4Temp': 119}   \n",
       "1    {'mGps': 698, 'mAcc': 677, 'e4Bvp': 689, 'e4Acc': 689, 'mGyr': 642, 'mMag': 642, 'e4Eda': 689, 'e4Hr': 688, 'e4Temp': 689}   \n",
       "..                                                                                                                          ...   \n",
       "466  {'mGps': 840, 'mAcc': 841, 'e4Bvp': 829, 'e4Acc': 829, 'mGyr': 841, 'mMag': 841, 'e4Eda': 829, 'e4Hr': 828, 'e4Temp': 829}   \n",
       "467  {'mGps': 753, 'mAcc': 740, 'e4Bvp': 743, 'e4Acc': 743, 'mGyr': 725, 'mMag': 754, 'e4Eda': 743, 'e4Hr': 743, 'e4Temp': 743}   \n",
       "\n",
       "                                                                 path  \n",
       "0    /workspace/human_understanding_2025/user01-06/user01/1598832660/  \n",
       "1    /workspace/human_understanding_2025/user01-06/user01/1599269580/  \n",
       "..                                                                ...  \n",
       "466  /workspace/human_understanding_2025/user26-30/user30/1600816380/  \n",
       "467  /workspace/human_understanding_2025/user26-30/user30/1600902660/  \n",
       "\n",
       "[468 rows x 8 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1mTrain Input Feature CSV File Path\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>date</th>\n",
       "      <th>count</th>\n",
       "      <th>folder</th>\n",
       "      <th>e4Hr</th>\n",
       "      <th>mGps</th>\n",
       "      <th>mAcc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>user01</td>\n",
       "      <td>2020-08-31</td>\n",
       "      <td>1</td>\n",
       "      <td>[/workspace/human_understanding_2025/user01-06/user01/1598832660/]</td>\n",
       "      <td>[[/workspace/human_understanding_2025/user01-06/user01/1598832660/e4Hr/1598874420.csv, /workspac...</td>\n",
       "      <td>[[/workspace/human_understanding_2025/user01-06/user01/1598832660/mGps/1598846940.csv, /workspac...</td>\n",
       "      <td>[[/workspace/human_understanding_2025/user01-06/user01/1598832660/mAcc/1598846940.csv, /workspac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>user01</td>\n",
       "      <td>2020-09-05</td>\n",
       "      <td>1</td>\n",
       "      <td>[/workspace/human_understanding_2025/user01-06/user01/1599269580/]</td>\n",
       "      <td>[[/workspace/human_understanding_2025/user01-06/user01/1599269580/e4Hr/1599279120.csv, /workspac...</td>\n",
       "      <td>[[/workspace/human_understanding_2025/user01-06/user01/1599269580/mGps/1599279120.csv, /workspac...</td>\n",
       "      <td>[[/workspace/human_understanding_2025/user01-06/user01/1599269580/mAcc/1599279120.csv, /workspac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>user30</td>\n",
       "      <td>2020-09-24</td>\n",
       "      <td>1</td>\n",
       "      <td>[/workspace/human_understanding_2025/user26-30/user30/1600816380/]</td>\n",
       "      <td>[[/workspace/human_understanding_2025/user26-30/user30/1600816380/e4Hr/1600820280.csv, /workspac...</td>\n",
       "      <td>[[/workspace/human_understanding_2025/user26-30/user30/1600816380/mGps/1600820280.csv, /workspac...</td>\n",
       "      <td>[[/workspace/human_understanding_2025/user26-30/user30/1600816380/mAcc/1600820280.csv, /workspac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>user30</td>\n",
       "      <td>2020-09-25</td>\n",
       "      <td>1</td>\n",
       "      <td>[/workspace/human_understanding_2025/user26-30/user30/1600902660/]</td>\n",
       "      <td>[[/workspace/human_understanding_2025/user26-30/user30/1600902660/e4Hr/1600918980.csv, /workspac...</td>\n",
       "      <td>[[/workspace/human_understanding_2025/user26-30/user30/1600902660/mGps/1600918980.csv, /workspac...</td>\n",
       "      <td>[[/workspace/human_understanding_2025/user26-30/user30/1600902660/mAcc/1600918980.csv, /workspac...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>390 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     userId        date  count  \\\n",
       "0    user01  2020-08-31      1   \n",
       "1    user01  2020-09-05      1   \n",
       "..      ...         ...    ...   \n",
       "388  user30  2020-09-24      1   \n",
       "389  user30  2020-09-25      1   \n",
       "\n",
       "                                                                 folder  \\\n",
       "0    [/workspace/human_understanding_2025/user01-06/user01/1598832660/]   \n",
       "1    [/workspace/human_understanding_2025/user01-06/user01/1599269580/]   \n",
       "..                                                                  ...   \n",
       "388  [/workspace/human_understanding_2025/user26-30/user30/1600816380/]   \n",
       "389  [/workspace/human_understanding_2025/user26-30/user30/1600902660/]   \n",
       "\n",
       "                                                                                                    e4Hr  \\\n",
       "0    [[/workspace/human_understanding_2025/user01-06/user01/1598832660/e4Hr/1598874420.csv, /workspac...   \n",
       "1    [[/workspace/human_understanding_2025/user01-06/user01/1599269580/e4Hr/1599279120.csv, /workspac...   \n",
       "..                                                                                                   ...   \n",
       "388  [[/workspace/human_understanding_2025/user26-30/user30/1600816380/e4Hr/1600820280.csv, /workspac...   \n",
       "389  [[/workspace/human_understanding_2025/user26-30/user30/1600902660/e4Hr/1600918980.csv, /workspac...   \n",
       "\n",
       "                                                                                                    mGps  \\\n",
       "0    [[/workspace/human_understanding_2025/user01-06/user01/1598832660/mGps/1598846940.csv, /workspac...   \n",
       "1    [[/workspace/human_understanding_2025/user01-06/user01/1599269580/mGps/1599279120.csv, /workspac...   \n",
       "..                                                                                                   ...   \n",
       "388  [[/workspace/human_understanding_2025/user26-30/user30/1600816380/mGps/1600820280.csv, /workspac...   \n",
       "389  [[/workspace/human_understanding_2025/user26-30/user30/1600902660/mGps/1600918980.csv, /workspac...   \n",
       "\n",
       "                                                                                                    mAcc  \n",
       "0    [[/workspace/human_understanding_2025/user01-06/user01/1598832660/mAcc/1598846940.csv, /workspac...  \n",
       "1    [[/workspace/human_understanding_2025/user01-06/user01/1599269580/mAcc/1599279120.csv, /workspac...  \n",
       "..                                                                                                   ...  \n",
       "388  [[/workspace/human_understanding_2025/user26-30/user30/1600816380/mAcc/1600820280.csv, /workspac...  \n",
       "389  [[/workspace/human_understanding_2025/user26-30/user30/1600902660/mAcc/1600918980.csv, /workspac...  \n",
       "\n",
       "[390 rows x 7 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1mTrain Feature CSV File\u001b[0m\n",
      "\u001b[1mExample: e4Hr\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>hr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>86.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>86.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>58.0</td>\n",
       "      <td>103.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>59.0</td>\n",
       "      <td>103.05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>60 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    timestamp      hr\n",
       "0         0.0   86.53\n",
       "1         1.0   86.75\n",
       "..        ...     ...\n",
       "58       58.0  103.02\n",
       "59       59.0  103.05\n",
       "\n",
       "[60 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1mTrain Label\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>date</th>\n",
       "      <th>Q1</th>\n",
       "      <th>Q2</th>\n",
       "      <th>Q3</th>\n",
       "      <th>S1</th>\n",
       "      <th>S2</th>\n",
       "      <th>S3</th>\n",
       "      <th>S4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>user01</td>\n",
       "      <td>2020-08-31</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>user01</td>\n",
       "      <td>2020-09-05</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>user30</td>\n",
       "      <td>2020-09-24</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>user30</td>\n",
       "      <td>2020-09-25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>390 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     userId        date  Q1  Q2  Q3  S1  S2  S3  S4\n",
       "0    user01  2020-08-31   0   0   0   0   1   1   1\n",
       "1    user01  2020-09-05   1   0   1   1   1   0   1\n",
       "..      ...         ...  ..  ..  ..  ..  ..  ..  ..\n",
       "388  user30  2020-09-24   1   0   1   0   1   1   1\n",
       "389  user30  2020-09-25   0   0   1   0   1   1   0\n",
       "\n",
       "[390 rows x 9 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_user_ids = []; all_user_Dts =[]; all_user_dates = []\n",
    "all_user_startPositions = []; all_user_endPositions = []\n",
    "user_match_folder_dfs = []\n",
    "\n",
    "user_features =[]; user_missing_features = []\n",
    "user_merge_label_Dt_dfs = []\n",
    "\n",
    "user_merge_input_dfs = []\n",
    "\n",
    "user_path_dfs = []\n",
    "\n",
    "user_label_dfs_for_csv = []\n",
    "\n",
    "for user_label_df, user_Dt_df, user_feature_df in zip(user_label_dfs, user_Dt_dfs, user_feature_dfs):\n",
    "    user_merge_label_Dt_df = pd.merge(user_label_df, user_Dt_df, left_on='date', right_on='date', how='inner')\n",
    "    user_merge_label_Dt_dfs.append(user_merge_label_Dt_df)\n",
    "\n",
    "    user_ids = []; user_Dts =[]; user_dates = []\n",
    "    user_startPositions = []; user_endPositions = []\n",
    "    for num_Dt in range(len(user_merge_label_Dt_df)):\n",
    "        row_Dt = user_merge_label_Dt_df.loc[num_Dt]\n",
    "        # startDt = int(row_Dt['startDt'])\n",
    "        # endDt = int(row_Dt['endDt'])\n",
    "        # lastUpdate = int(row_Dt['lastUpdate'])\n",
    "\n",
    "        date = row_Dt['date']\n",
    "        startPosition = int(row_Dt['startPosition'])\n",
    "        endPosition = int(row_Dt['endPosition'])\n",
    "\n",
    "        for num_folder in range(len(user_feature_df)):\n",
    "            row_folder = user_feature_df.loc[num_folder]\n",
    "            dt = int(row_folder['Dt'])\n",
    "            if dt >= startPosition and dt <= endPosition:\n",
    "                user_id = row_folder['userId']\n",
    "                user_date = date\n",
    "                user_Dt = row_folder['Dt']\n",
    "\n",
    "                user_ids.append(user_id)\n",
    "                user_dates.append(date)\n",
    "                user_Dts.append(user_Dt)\n",
    "                user_startPositions.append(startPosition)\n",
    "                user_endPositions.append(endPosition)\n",
    "\n",
    "\n",
    "    user_match_folder_df = pd.DataFrame({\"userId\":user_ids, \"date\":user_dates,\n",
    "                                        \"Dt\":user_Dts, \"startPosition\":user_startPositions, \"endPosition\":user_endPositions})\n",
    "    user_match_folder_dfs.append(user_match_folder_df)\n",
    "\n",
    "\n",
    "for user_match_folder_df, user_merge_label_Dt_df, user_feature_df, user_label_df in zip(user_match_folder_dfs, user_merge_label_Dt_dfs, user_feature_dfs, user_label_dfs):                                                                                 \n",
    "    user_merge_input_df = pd.merge(user_match_folder_df, user_merge_label_Dt_df, left_on='startPosition', right_on='startPosition', how='inner')\n",
    "    user_merge_input_df = user_merge_input_df.sort_values(\"date_x\")\n",
    "    del user_merge_input_df['userId_x']\n",
    "    \n",
    "    user_merge_input_df = pd.merge(user_merge_input_df, user_feature_df, left_on='Dt', right_on='Dt', how='inner')\n",
    "    user_merge_input_df = user_merge_input_df[['userId_x', 'date_x', 'Dt', 'startPosition', 'endPosition_x', 'missing feature', 'feature', 'path']]\n",
    "    user_merge_input_df.columns = ['userId', 'date', 'Dt', 'startPosition', 'endPosition', 'missing feature', 'feature', 'path']\n",
    "    user_merge_input_df = user_merge_input_df.sort_values(\"date\")\n",
    "    user_merge_input_dfs.append(user_merge_input_df)\n",
    "\n",
    "    dates = sorted(list(user_merge_input_df['date'].value_counts().keys()))\n",
    "    user_ids = list(user_merge_input_df['userId'].value_counts().keys()) * len(dates)\n",
    "    user_folders = []; counts = []\n",
    "    user_hrate_csv_lists = []\n",
    "    user_mgps_csv_lists = []\n",
    "    user_macc_csv_lists = []\n",
    "\n",
    "    for date in dates:\n",
    "        user_split_date_df = user_merge_input_df.loc[user_merge_input_df.date == date] \n",
    "        user_folder = list(user_split_date_df['path'])  \n",
    "        user_folder = sorted(user_folder)\n",
    "        count = len(user_folder)\n",
    "        counts.append(count) \n",
    "        user_folders.append(user_folder)\n",
    "\n",
    "        user_hrate_folders = []; user_hrate_date_csv_lists = []\n",
    "        user_mgps_folders = []; user_mgps_date_csv_lists = []\n",
    "        user_macc_folders = []; user_macc_date_csv_lists = []\n",
    "\n",
    "        feature_names = ['e4Hr', 'mGps', 'mAcc']\n",
    "\n",
    "        for feature_name in feature_names:\n",
    "            for user_folder_name in user_folder:\n",
    "                \n",
    "                if feature_name == 'e4Hr':\n",
    "                    user_hrate_folder = user_folder_name + feature_name\n",
    "                    user_hrate_folders.append(user_hrate_folder)\n",
    "                    user_hrate_date_csv_list = glob.glob(user_hrate_folder + \"/*.csv\")\n",
    "                    user_hrate_date_csv_lists.append(user_hrate_date_csv_list)\n",
    "\n",
    "                elif feature_name == 'mGps':\n",
    "                    user_mgps_folder = user_folder_name + feature_name\n",
    "                    user_mgps_folders.append(user_mgps_folder)\n",
    "                    user_mgps_date_csv_list = glob.glob(user_mgps_folder + \"/*.csv\")\n",
    "                    user_mgps_date_csv_lists.append(user_mgps_date_csv_list)\n",
    "\n",
    "                elif feature_name == 'mAcc': \n",
    "                    user_macc_folder = user_folder_name + feature_name\n",
    "                    user_macc_folders.append(user_macc_folder)\n",
    "                    user_macc_date_csv_list = glob.glob(user_macc_folder + \"/*.csv\")\n",
    "                    user_macc_date_csv_lists.append(user_macc_date_csv_list)\n",
    "\n",
    "        user_hrate_csv_lists.append(user_hrate_date_csv_lists)\n",
    "        user_mgps_csv_lists.append(user_mgps_date_csv_lists)\n",
    "        user_macc_csv_lists.append(user_macc_date_csv_lists)\n",
    "\n",
    "    user_path_df = pd.DataFrame({\"userId\":user_ids, \"date\":dates, \"count\":counts, \"folder\":user_folders,\n",
    "                                 \"e4Hr\":user_hrate_csv_lists, \"mGps\":user_mgps_csv_lists, 'mAcc':user_macc_csv_lists})\n",
    "    user_path_dfs.append(user_path_df)\n",
    "\n",
    "    user_label_df = pd.merge(user_path_df, user_label_df, left_on='date', right_on='date', how='inner')\n",
    "    user_label_df = user_label_df.sort_values(\"date\")\n",
    "    user_label_df = user_label_df[[\"userId_x\", \"date\", \"Q1\", \"Q2\", \"Q3\", \"S1\", \"S2\", \"S3\", \"S4\"]]\n",
    "    user_label_df.columns = ['userId', \"date\", \"Q1\", \"Q2\", \"Q3\", \"S1\", \"S2\", \"S3\", \"S4\"]\n",
    "    user_label_dfs_for_csv.append(user_label_df)\n",
    "\n",
    "all_user_match_folder_df = pd.concat(user_match_folder_dfs, axis=0).reset_index(drop=True)   \n",
    "all_user_label_Dt_df = pd.concat(user_merge_label_Dt_dfs, axis=0).reset_index(drop=True)   \n",
    "all_user_input_info_df = pd.concat(user_merge_input_dfs, axis=0).reset_index(drop=True)  \n",
    "all_user_path_df = pd.concat(user_path_dfs, axis=0).reset_index(drop=True)  \n",
    "all_user_label_df = pd.concat(user_label_dfs_for_csv, axis=0).reset_index(drop=True)  \n",
    "all_user_input_info_df.to_csv(\"workspace/data/train_input_info.csv\", index=False)\n",
    "all_user_label_df.to_csv(\"workspace/data/train_label.csv\", index=False)\n",
    "\n",
    "pd.set_option('display.max_rows', 4)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "print(colored(\"Matched Folder\", attrs=['bold']))\n",
    "display(all_user_match_folder_df)\n",
    "print()\n",
    "\n",
    "pd.set_option('display.max_rows', 4)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "print(colored(\"Train Input Information\", attrs=['bold']))\n",
    "display(all_user_input_info_df)     \n",
    "print()\n",
    "\n",
    "pd.set_option('display.max_rows', 4)\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "print(colored(\"Train Input Feature CSV File Path\", attrs=['bold']))\n",
    "display(all_user_path_df)     \n",
    "print()\n",
    "\n",
    "print(colored(\"Train Feature CSV File\", attrs=['bold']))\n",
    "print(colored(\"Example: e4Hr\", attrs=['bold']))\n",
    "pd.set_option('display.max_rows', 4)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "csv_e4Hr = all_user_path_df['e4Hr']\n",
    "for i, csv_nested_list in enumerate(csv_e4Hr):\n",
    "    for j, csv_list in enumerate(csv_nested_list):\n",
    "        for k, csv in enumerate(csv_list):\n",
    "            if i == 0 and j == 0 and k == 0:\n",
    "                user_feature_csv_example_df = pd.read_csv(csv)\n",
    "                display(user_feature_csv_example_df)\n",
    "                print()\n",
    "\n",
    "pd.set_option('display.max_rows', 4)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "print(colored(\"Train Label\", attrs=['bold']))\n",
    "display(all_user_label_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.5.0 wHr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 390/390 [02:43<00:00,  2.38it/s]\n"
     ]
    }
   ],
   "source": [
    "def make_average_list(data, length): \n",
    "    average_list = []\n",
    "    for i in range(0, len(data), length): \n",
    "        nested_list = data[i:i + length]\n",
    "        netsed_mean = np.mean(nested_list)\n",
    "        average_list.append(netsed_mean)\n",
    "    return average_list\n",
    "\n",
    "wHr_lists = []; remove_index = []\n",
    "csv_e4Hr = all_user_path_df['e4Hr']\n",
    "idx = -1\n",
    "\n",
    "with tqdm.tqdm(csv_e4Hr) as pbar:\n",
    "    for csv_nested_list in pbar:\n",
    "        idx += 1\n",
    "        wHr_date_lists = []\n",
    "        for j, csv_list in enumerate(csv_nested_list):\n",
    "            for k, csv in enumerate(csv_list):\n",
    "                user_feature_csv_example_df = pd.read_csv(csv)\n",
    "                user_feature_csv_example_df = user_feature_csv_example_df[(user_feature_csv_example_df['hr'] != 0)]\n",
    "                wHr_list = list(user_feature_csv_example_df['hr'])\n",
    "                wHr_list = make_average_list(wHr_list, 50)\n",
    "                wHr_date_lists.append(wHr_list)\n",
    "        wHr_date_lists = sum(wHr_date_lists, []) \n",
    "        wHr_date_lists = make_average_list(wHr_date_lists, 50)\n",
    "        if len(wHr_date_lists) == 0:\n",
    "            remove_index.append(idx)\n",
    "            pass\n",
    "        elif len(wHr_date_lists) != 0:\n",
    "            wHr_lists.append(wHr_date_lists)\n",
    "        \n",
    "all_user_wHr_df = all_user_path_df[['userId', 'date']]\n",
    "all_user_wHr_df = all_user_wHr_df.drop(index=remove_index)\n",
    "all_user_wHr_df = all_user_wHr_df.reset_index()\n",
    "del all_user_wHr_df['index'] \n",
    "all_user_wHr_df['hr'] = wHr_lists\n",
    "all_user_wHr_df.to_csv(\"workspace/data/train_wHr_input.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mTrain wHr\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>date</th>\n",
       "      <th>hr</th>\n",
       "      <th>Q1</th>\n",
       "      <th>Q2</th>\n",
       "      <th>Q3</th>\n",
       "      <th>S1</th>\n",
       "      <th>S2</th>\n",
       "      <th>S3</th>\n",
       "      <th>S4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>user01</td>\n",
       "      <td>2020-08-31</td>\n",
       "      <td>[86.500984, 87.74435600000002, 86.43617274074074, 89.721256, 90.36156666666668]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>user01</td>\n",
       "      <td>2020-09-05</td>\n",
       "      <td>[87.484928, 85.21238755555554, 86.728824, 89.728356, 90.956332, 87.33840533333333, 84.615324, 84...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377</th>\n",
       "      <td>user30</td>\n",
       "      <td>2020-09-24</td>\n",
       "      <td>[78.25824399999999, 80.19544, 77.76200399999999, 81.45235600000001, 78.67375200000001, 81.138328...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378</th>\n",
       "      <td>user30</td>\n",
       "      <td>2020-09-25</td>\n",
       "      <td>[80.138268, 79.45635936507936, 81.50123199999999, 78.75182799999999, 76.837956, 80.69712, 80.258...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>379 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     userId        date  \\\n",
       "0    user01  2020-08-31   \n",
       "1    user01  2020-09-05   \n",
       "..      ...         ...   \n",
       "377  user30  2020-09-24   \n",
       "378  user30  2020-09-25   \n",
       "\n",
       "                                                                                                      hr  \\\n",
       "0                        [86.500984, 87.74435600000002, 86.43617274074074, 89.721256, 90.36156666666668]   \n",
       "1    [87.484928, 85.21238755555554, 86.728824, 89.728356, 90.956332, 87.33840533333333, 84.615324, 84...   \n",
       "..                                                                                                   ...   \n",
       "377  [78.25824399999999, 80.19544, 77.76200399999999, 81.45235600000001, 78.67375200000001, 81.138328...   \n",
       "378  [80.138268, 79.45635936507936, 81.50123199999999, 78.75182799999999, 76.837956, 80.69712, 80.258...   \n",
       "\n",
       "     Q1  Q2  Q3  S1  S2  S3  S4  \n",
       "0     0   0   0   0   1   1   1  \n",
       "1     1   0   1   1   1   0   1  \n",
       "..   ..  ..  ..  ..  ..  ..  ..  \n",
       "377   1   0   1   0   1   1   1  \n",
       "378   0   0   1   0   1   1   0  \n",
       "\n",
       "[379 rows x 10 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "all_user_wHr_df = pd.read_csv(\"workspace/data/train_wHr_input.csv\")\n",
    "all_user_label_df = pd.read_csv(\"workspace/data/train_label.csv\")\n",
    "all_user_wHr_df = all_user_wHr_df.merge(all_user_label_df)\n",
    "\n",
    "all_user_wHr_df.to_csv(\"workspace/data/train_wHr_data.csv\", index=False)\n",
    "\n",
    "pd.set_option('display.max_rows', 4)\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "print(colored(\"Train wHr\", attrs=['bold']))\n",
    "display(all_user_wHr_df)     \n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.5.1 mGps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 390/390 [04:02<00:00,  1.61it/s]\n"
     ]
    }
   ],
   "source": [
    "def make_average_list(data, length): \n",
    "    average_list = []\n",
    "    for i in range(0, len(data), length): \n",
    "        nested_list = data[i:i + length]\n",
    "        netsed_mean = np.mean(nested_list)\n",
    "        average_list.append(netsed_mean)\n",
    "    return average_list\n",
    "\n",
    "lat_lists = []; lon_lists = []; remove_index = []\n",
    "csv_mGps = all_user_path_df['mGps']\n",
    "idx = -1\n",
    "\n",
    "with tqdm.tqdm(csv_mGps) as pbar:\n",
    "    for csv_nested_list in pbar:\n",
    "        idx += 1\n",
    "        lat_date_lists = []; lon_date_lists = []\n",
    "        for j, csv_list in enumerate(csv_nested_list):\n",
    "            for k, csv in enumerate(csv_list):\n",
    "                user_feature_csv_example_df = pd.read_csv(csv)\n",
    "                user_feature_csv_example_df = user_feature_csv_example_df[(user_feature_csv_example_df['lat'] != 0) & (user_feature_csv_example_df['lon'] != 0)]\n",
    "               \n",
    "                lat_list = list(user_feature_csv_example_df['lat'])\n",
    "                lat_date_lists.append(lat_list)\n",
    "                    \n",
    "                lon_list = list(user_feature_csv_example_df['lon'])\n",
    "                lon_date_lists.append(lon_list)\n",
    "                \n",
    "        lat_date_lists = sum(lat_date_lists, []) \n",
    "        lat_date_lists = make_average_list(lat_date_lists, 50)\n",
    "\n",
    "        lon_date_lists = sum(lon_date_lists, []) \n",
    "        lon_date_lists = make_average_list(lon_date_lists, 50)   \n",
    "\n",
    "        if len(lat_date_lists) == 0 or len(lon_date_lists) == 0:\n",
    "            remove_index.append(idx)\n",
    "            pass\n",
    "        else:\n",
    "            lat_lists.append(lat_date_lists)\n",
    "            lon_lists.append(lon_date_lists)                    \n",
    "        \n",
    "all_user_mGps_df = all_user_path_df[['userId', 'date']]\n",
    "all_user_mGps_df = all_user_mGps_df.drop(index=remove_index)\n",
    "all_user_mGps_df = all_user_mGps_df.reset_index()\n",
    "del all_user_mGps_df['index'] \n",
    "all_user_mGps_df['lat'] = lat_lists\n",
    "all_user_mGps_df['lon'] = lon_lists\n",
    "all_user_mGps_df.to_csv(\"workspace/data/train_mGps_input.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mTrain wHr\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>date</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>Q1</th>\n",
       "      <th>Q2</th>\n",
       "      <th>Q3</th>\n",
       "      <th>S1</th>\n",
       "      <th>S2</th>\n",
       "      <th>S3</th>\n",
       "      <th>S4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>user01</td>\n",
       "      <td>2020-08-31</td>\n",
       "      <td>[37.428727606, 37.373258362, 37.45968430600001, 37.441553966, 37.439966222, 37.483896382000005, ...</td>\n",
       "      <td>[127.06283952599999, 127.035457894, 127.037780458, 126.981853632, 126.98031775800001, 127.013245...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>user01</td>\n",
       "      <td>2020-09-05</td>\n",
       "      <td>[37.483967086, 37.486892482, 37.484844412, 37.482705612, 37.48434709400001, 37.483589436, 37.485...</td>\n",
       "      <td>[127.01222557400003, 127.000313692, 126.996643608, 126.974013362, 127.00607272999997, 127.012433...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>user30</td>\n",
       "      <td>2020-09-24</td>\n",
       "      <td>[37.48705599, 37.48724637, 37.486589011999996, 37.487062484, 37.48705531, 37.487036232, 37.48686...</td>\n",
       "      <td>[126.89534209399999, 126.866566006, 126.88410588199999, 126.886156966, 126.89534959400002, 126.8...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>user30</td>\n",
       "      <td>2020-09-25</td>\n",
       "      <td>[37.487034374, 37.485593026, 37.487086408, 37.487099118, 37.48448434, 37.486945552, 37.487054703...</td>\n",
       "      <td>[126.876101378, 126.88212281200002, 126.895381506, 126.895346558, 126.871686934, 126.86689568999...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>360 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     userId        date  \\\n",
       "0    user01  2020-08-31   \n",
       "1    user01  2020-09-05   \n",
       "..      ...         ...   \n",
       "358  user30  2020-09-24   \n",
       "359  user30  2020-09-25   \n",
       "\n",
       "                                                                                                     lat  \\\n",
       "0    [37.428727606, 37.373258362, 37.45968430600001, 37.441553966, 37.439966222, 37.483896382000005, ...   \n",
       "1    [37.483967086, 37.486892482, 37.484844412, 37.482705612, 37.48434709400001, 37.483589436, 37.485...   \n",
       "..                                                                                                   ...   \n",
       "358  [37.48705599, 37.48724637, 37.486589011999996, 37.487062484, 37.48705531, 37.487036232, 37.48686...   \n",
       "359  [37.487034374, 37.485593026, 37.487086408, 37.487099118, 37.48448434, 37.486945552, 37.487054703...   \n",
       "\n",
       "                                                                                                     lon  \\\n",
       "0    [127.06283952599999, 127.035457894, 127.037780458, 126.981853632, 126.98031775800001, 127.013245...   \n",
       "1    [127.01222557400003, 127.000313692, 126.996643608, 126.974013362, 127.00607272999997, 127.012433...   \n",
       "..                                                                                                   ...   \n",
       "358  [126.89534209399999, 126.866566006, 126.88410588199999, 126.886156966, 126.89534959400002, 126.8...   \n",
       "359  [126.876101378, 126.88212281200002, 126.895381506, 126.895346558, 126.871686934, 126.86689568999...   \n",
       "\n",
       "     Q1  Q2  Q3  S1  S2  S3  S4  \n",
       "0     0   0   0   0   1   1   1  \n",
       "1     1   0   1   1   1   0   1  \n",
       "..   ..  ..  ..  ..  ..  ..  ..  \n",
       "358   1   0   1   0   1   1   1  \n",
       "359   0   0   1   0   1   1   0  \n",
       "\n",
       "[360 rows x 11 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "all_user_mGps_df = pd.read_csv(\"workspace/data/train_mGps_input.csv\")\n",
    "all_user_label_df = pd.read_csv(\"workspace/data/train_label.csv\")\n",
    "all_user_mGps_df = all_user_mGps_df.merge(all_user_label_df)\n",
    "\n",
    "all_user_mGps_df.to_csv(\"workspace/data/train_mGps_data.csv\", index=False)\n",
    "\n",
    "pd.set_option('display.max_rows', 4)\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "print(colored(\"Train wHr\", attrs=['bold']))\n",
    "display(all_user_mGps_df)     \n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.5.2 mAcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1/22: 100%|██████████| 10/10 [01:41<00:00, 10.12s/it]\n",
      "2/22: 100%|██████████| 10/10 [03:08<00:00, 18.83s/it]\n",
      "3/22: 100%|██████████| 7/7 [11:31<00:00, 98.72s/it] \n",
      "4/22: 100%|██████████| 24/24 [04:30<00:00, 11.28s/it]\n",
      "5/22: 100%|██████████| 26/26 [00:23<00:00,  1.13it/s]\n",
      "6/22: 100%|██████████| 26/26 [05:01<00:00, 11.59s/it]\n",
      "7/22: 100%|██████████| 20/20 [07:13<00:00, 21.66s/it]\n",
      "8/22: 100%|██████████| 10/10 [10:15<00:00, 61.58s/it]\n",
      "9/22: 100%|██████████| 19/19 [04:28<00:00, 14.16s/it]\n",
      "10/22: 100%|██████████| 19/19 [04:50<00:00, 15.30s/it]\n",
      "11/22: 100%|██████████| 10/10 [15:30<00:00, 93.06s/it]\n",
      "12/22: 100%|██████████| 18/18 [06:04<00:00, 20.24s/it]\n",
      "13/22: 100%|██████████| 18/18 [03:52<00:00, 12.94s/it]\n",
      "14/22: 100%|██████████| 16/16 [01:07<00:00,  4.21s/it]\n",
      "15/22: 100%|██████████| 26/26 [05:29<00:00, 12.66s/it]\n",
      "16/22: 100%|██████████| 27/27 [05:25<00:00, 12.06s/it]\n",
      "17/22: 100%|██████████| 22/22 [00:00<00:00, 52.97it/s]\n",
      "18/22: 100%|██████████| 20/20 [05:22<00:00, 16.12s/it]\n",
      "19/22: 100%|██████████| 16/16 [00:46<00:00,  2.89s/it]\n",
      "20/22: 100%|██████████| 18/18 [07:38<00:00, 25.46s/it]\n",
      "21/22: 100%|██████████| 6/6 [08:17<00:00, 82.93s/it] \n",
      "22/22: 100%|██████████| 22/22 [05:33<00:00, 15.16s/it]\n"
     ]
    }
   ],
   "source": [
    "def make_average_list(data, length): \n",
    "    average_list = []\n",
    "    for i in range(0, len(data), length): \n",
    "        nested_list = data[i:i + length]\n",
    "        netsed_mean = np.mean(nested_list)\n",
    "        average_list.append(netsed_mean)\n",
    "    return average_list\n",
    "\n",
    "def divide_df(l): \n",
    "    nested_df = []; nested_lens = []\n",
    "    users = sorted(list(set(list(l['userId']))))\n",
    "    for user in users:\n",
    "        user_label = l['userId'] == user   \n",
    "        user_label_df = l[user_label]\n",
    "        user_label_df = user_label_df.reset_index()\n",
    "        del user_label_df['index']\n",
    "        nested_len = len(user_label_df)\n",
    "        nested_df.append(user_label_df)\n",
    "        nested_lens.append(nested_len)\n",
    "    return nested_df, nested_lens\n",
    "\n",
    "all_user_label_df = pd.read_csv(\"workspace/data/train_label.csv\")\n",
    "all_user_label_nested_df, nested_lens = divide_df(all_user_label_df)\n",
    "\n",
    "all_user_mAcc_df = all_user_path_df[['userId', 'date']]\n",
    "all_user_mAcc_nested_df, nested_lens = divide_df(all_user_mAcc_df)\n",
    "\n",
    "csv_nested_mAcc_path = []\n",
    "csv_nested_mAcc, nested_lens = divide_df(all_user_path_df)\n",
    "for csv_mAcc in csv_nested_mAcc:\n",
    "    csv_nested_mAcc_path.append(list(csv_mAcc['mAcc']))\n",
    "\n",
    "for idx, (csv_mAcc_path, all_user_label_df, all_user_mAcc_df) in enumerate(zip(csv_nested_mAcc_path, all_user_label_nested_df, all_user_mAcc_nested_df)):\n",
    "    # if idx >= 16:\n",
    "    x_lists = []; y_lists = []; z_lists = []; remove_index = []\n",
    "    remove_idx = -1\n",
    "    with tqdm.tqdm(csv_mAcc_path) as pbar:\n",
    "        pbar.set_description(f'{idx + 1}/{len(all_user_mAcc_nested_df)}')\n",
    "        for csv_nested_list in pbar:\n",
    "            remove_idx += 1\n",
    "            x_folder_lists = []; y_folder_lists = []; z_folder_lists = []\n",
    "            for j, csv_list in enumerate(csv_nested_list):\n",
    "                for k, csv in enumerate(csv_list):\n",
    "                    user_feature_csv_example_df = pd.read_csv(csv)\n",
    "                    user_feature_csv_example_df = user_feature_csv_example_df[(user_feature_csv_example_df['x'] != 0) & (user_feature_csv_example_df['y'] != 0) & (user_feature_csv_example_df['z'] != 0)]\n",
    "                    x_list = list(user_feature_csv_example_df['x'])\n",
    "                    x_folder_lists.append(x_list)\n",
    "                    y_list = list(user_feature_csv_example_df['y'])\n",
    "                    y_folder_lists.append(y_list)\n",
    "                    z_list = list(user_feature_csv_example_df['z'])\n",
    "                    z_folder_lists.append(z_list)                   \n",
    "            x_date_lists = sum(x_folder_lists, []) \n",
    "            y_date_lists = sum(y_folder_lists, [])  \n",
    "            z_date_lists = sum(z_folder_lists, []) \n",
    "\n",
    "            x_date_lists = make_average_list(x_date_lists, 50)\n",
    "            y_date_lists = make_average_list(y_date_lists, 50)\n",
    "            z_date_lists = make_average_list(z_date_lists, 50)\n",
    "\n",
    "            if len(x_date_lists) == 0 or len(y_date_lists) == 0 or len(z_date_lists) == 0:\n",
    "                remove_index.append(remove_idx)\n",
    "                pass\n",
    "            else:\n",
    "                x_lists.append(x_date_lists)\n",
    "                y_lists.append(y_date_lists)\n",
    "                z_lists.append(z_date_lists)\n",
    "\n",
    "        all_user_mAcc_df = all_user_mAcc_df.drop(index=remove_index)\n",
    "        all_user_mAcc_df = all_user_mAcc_df.reset_index()\n",
    "        del all_user_mAcc_df['index'] \n",
    "        all_user_mAcc_df['x'] = x_lists\n",
    "        all_user_mAcc_df['y'] = y_lists\n",
    "        all_user_mAcc_df['z'] = z_lists\n",
    "        all_user_mAcc_df = all_user_mAcc_df.merge(all_user_label_df)\n",
    "        if idx < 9: idx = \"0\" + str(idx+1)\n",
    "        elif idx >= 9: idx = str(idx+1)\n",
    "        all_user_mAcc_df.to_csv(\"workspace/data/train_mAcc_data_\" + idx + \".csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mTrain mAcc\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>date</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>Q1</th>\n",
       "      <th>Q2</th>\n",
       "      <th>Q3</th>\n",
       "      <th>S1</th>\n",
       "      <th>S2</th>\n",
       "      <th>S3</th>\n",
       "      <th>S4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>user01</td>\n",
       "      <td>2020-08-31</td>\n",
       "      <td>[0.027773587904000002, 0.031508656592, 0.029593237011999996, 0.028779183128, 0.027821473508, 0.0...</td>\n",
       "      <td>[0.1482056118, 0.1452845969, 0.14499728316000002, 0.14878023720000003, 0.1552926648, 0.141166443...</td>\n",
       "      <td>[9.72238382, 9.7270767, 9.72482599, 9.723437259999999, 9.725256889999999, 9.7290878, 9.72808216,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>user01</td>\n",
       "      <td>2020-09-05</td>\n",
       "      <td>[-2.215039396, -2.22849521, -2.230362774, -2.3605634220000002, -2.307027428, -2.275997646, -2.28...</td>\n",
       "      <td>[-9.41017044, -9.413666000000001, -9.39398513, -9.344663109999999, -9.37176624, -9.37574079, -9....</td>\n",
       "      <td>[1.3032516680000001, 1.25627598, 1.3568355300000001, 1.492830336, 1.3840344999999998, 1.39720301...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>user01</td>\n",
       "      <td>2020-09-24</td>\n",
       "      <td>[0.22300275619999999, 0.22012962780000003, 0.22429566579999996, 0.22405623859999999, 0.222954872...</td>\n",
       "      <td>[8.629349619999998, 8.62762565, 8.62958903, 8.63069033, 8.628248150000001, 8.62920587, 8.6280087...</td>\n",
       "      <td>[4.366630546, 4.36361375, 4.365433417999999, 4.365912302, 4.3645236, 4.367827694, 4.363470104, 4...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>user01</td>\n",
       "      <td>2020-09-26</td>\n",
       "      <td>[-0.509070712, -0.6214579671999999, -0.5076341472000001, 0.6235649328799999, 0.37829541972, -0.8...</td>\n",
       "      <td>[-9.811929739999998, -9.79770775, -9.81580837, -9.812216990000001, -9.76394851, -9.6632931199999...</td>\n",
       "      <td>[-1.0088516412, -1.0296818282, -0.8390017803599998, -0.7917387918799998, -1.5652811028, -1.93534...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    userId        date  \\\n",
       "0   user01  2020-08-31   \n",
       "1   user01  2020-09-05   \n",
       "..     ...         ...   \n",
       "8   user01  2020-09-24   \n",
       "9   user01  2020-09-26   \n",
       "\n",
       "                                                                                                      x  \\\n",
       "0   [0.027773587904000002, 0.031508656592, 0.029593237011999996, 0.028779183128, 0.027821473508, 0.0...   \n",
       "1   [-2.215039396, -2.22849521, -2.230362774, -2.3605634220000002, -2.307027428, -2.275997646, -2.28...   \n",
       "..                                                                                                  ...   \n",
       "8   [0.22300275619999999, 0.22012962780000003, 0.22429566579999996, 0.22405623859999999, 0.222954872...   \n",
       "9   [-0.509070712, -0.6214579671999999, -0.5076341472000001, 0.6235649328799999, 0.37829541972, -0.8...   \n",
       "\n",
       "                                                                                                      y  \\\n",
       "0   [0.1482056118, 0.1452845969, 0.14499728316000002, 0.14878023720000003, 0.1552926648, 0.141166443...   \n",
       "1   [-9.41017044, -9.413666000000001, -9.39398513, -9.344663109999999, -9.37176624, -9.37574079, -9....   \n",
       "..                                                                                                  ...   \n",
       "8   [8.629349619999998, 8.62762565, 8.62958903, 8.63069033, 8.628248150000001, 8.62920587, 8.6280087...   \n",
       "9   [-9.811929739999998, -9.79770775, -9.81580837, -9.812216990000001, -9.76394851, -9.6632931199999...   \n",
       "\n",
       "                                                                                                      z  \\\n",
       "0   [9.72238382, 9.7270767, 9.72482599, 9.723437259999999, 9.725256889999999, 9.7290878, 9.72808216,...   \n",
       "1   [1.3032516680000001, 1.25627598, 1.3568355300000001, 1.492830336, 1.3840344999999998, 1.39720301...   \n",
       "..                                                                                                  ...   \n",
       "8   [4.366630546, 4.36361375, 4.365433417999999, 4.365912302, 4.3645236, 4.367827694, 4.363470104, 4...   \n",
       "9   [-1.0088516412, -1.0296818282, -0.8390017803599998, -0.7917387918799998, -1.5652811028, -1.93534...   \n",
       "\n",
       "    Q1  Q2  Q3  S1  S2  S3  S4  \n",
       "0    0   0   0   0   1   1   1  \n",
       "1    1   0   1   1   1   0   1  \n",
       "..  ..  ..  ..  ..  ..  ..  ..  \n",
       "8    0   0   1   0   1   1   1  \n",
       "9    0   0   1   0   1   0   1  \n",
       "\n",
       "[10 rows x 12 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "all_user_mAcc_df = pd.read_csv(\"workspace/data/train_mAcc_data_01.csv\")\n",
    "pd.set_option('display.max_rows', 4)\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "print(colored(\"Train mAcc\", attrs=['bold']))\n",
    "display(all_user_mAcc_df)     \n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.0.0 Validation & Test Datset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.0 Validation & Test Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_label_path = \"workspace/human_understanding_2024/val_label.csv\"\n",
    "test_label_path = \"workspace/human_understanding_2024/answer_sample.csv\"\n",
    "\n",
    "df_val_label = pd.read_csv(val_label_path)\n",
    "df_test_label = pd.read_csv(test_label_path)\n",
    "\n",
    "print(colored(\"Validation Label\", attrs=['bold']))\n",
    "pd.set_option('display.max_rows', 4)\n",
    "df_val_label.columns = ['userId', 'date', 'Q1', 'Q2', 'Q3', 'S1', 'S2', 'S3', 'S4']\n",
    "display(df_val_label)\n",
    "print()\n",
    "\n",
    "print(colored(\"Test Label\", attrs=['bold']))\n",
    "pd.set_option('display.max_rows', 4)\n",
    "df_test_label.columns = ['userId', 'date', 'Q1', 'Q2', 'Q3', 'S1', 'S2', 'S3', 'S4']\n",
    "display(df_test_label)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.0 wHr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "스마트워치(갤럭시 워치)에서 측정된 심박 데이터. 1초 간격으로 측정됨."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_average_list(data, length): \n",
    "    average_list = []\n",
    "    for i in range(0, len(data), length): \n",
    "        nested_list = data[i:i + length]\n",
    "        netsed_mean = np.mean(nested_list)\n",
    "        average_list.append(netsed_mean)\n",
    "    return average_list\n",
    "\n",
    "val_dataset_path = \"workspace/human_understanding_2024/val_dataset\"\n",
    "test_dataset_path = \"workspace/human_understanding_2024/test_dataset\"\n",
    "\n",
    "valid_file_name = \"ch2024_val__w_heart_rate.parquet.gzip\"\n",
    "test_file_name = \"ch2024_test_w_heart_rate.parquet.gzip\"\n",
    "\n",
    "val_label_path = \"workspace/human_understanding_2024/val_label.csv\"\n",
    "test_label_path = \"workspace/human_understanding_2024/answer_sample.csv\"\n",
    "\n",
    "df_val_label = pd.read_csv(val_label_path)\n",
    "df_test_label = pd.read_csv(test_label_path)\n",
    "\n",
    "valid_hrate_df = pd.read_parquet(os.path.join(val_dataset_path, valid_file_name))\n",
    "test_hrate_df  = pd.read_parquet(os.path.join(test_dataset_path, test_file_name))\n",
    "\n",
    "valid_hrate_df  = valid_hrate_df [(valid_hrate_df ['heart_rate'] != 0)]\n",
    "test_hrate_df = test_hrate_df[(test_hrate_df['heart_rate'] != 0)]\n",
    "\n",
    "valid_hrate_df[\"timestamp\"] = valid_hrate_df[\"timestamp\"].astype(str)\n",
    "valid_hrate_df[['date', 'timestamp']] = valid_hrate_df['timestamp'].str.split(' ', expand=True)\n",
    "valid_hrate_df = valid_hrate_df[['subject_id', \"date\", \"timestamp\", \"heart_rate\"]]\n",
    "valid_hrate_df.columns = ['userId', \"date\", \"timestamp\", \"hr\"]\n",
    "\n",
    "user_valid_hrate_dfs = []\n",
    "valid_sleep_users = sorted(list(set(list(valid_hrate_df['userId']))))\n",
    "with tqdm.tqdm(valid_sleep_users) as pbar:\n",
    "    pbar.set_description('Validation Data')\n",
    "    for valid_sleep_user in pbar:\n",
    "        user_valid_hrate = valid_hrate_df['userId'] == valid_sleep_user   \n",
    "        user_valid_hrate_df = valid_hrate_df[user_valid_hrate]\n",
    "        dates = sorted(list(user_valid_hrate_df['date'].value_counts().keys()))\n",
    "\n",
    "        wHr_lists = []; remove_index = []\n",
    "        idx = -1\n",
    "        for date in dates:\n",
    "            idx += 1\n",
    "            user_split_valid_hrate_df = user_valid_hrate_df.loc[user_valid_hrate_df.date == date]\n",
    "            wHr_date_list = list(user_split_valid_hrate_df['hr'])\n",
    "            wHr_date_list = make_average_list(wHr_date_list, 50)\n",
    "            if len(wHr_date_list) == 0:\n",
    "                remove_index.append(idx)\n",
    "                pass\n",
    "            elif len(wHr_date_list) != 0:\n",
    "                wHr_lists.append(wHr_date_list)\n",
    "        \n",
    "        user_valid_hrate_df = pd.DataFrame({\"userId\":valid_sleep_user, \"date\":dates})\n",
    "        user_valid_hrate_df = user_valid_hrate_df.drop(index=remove_index)\n",
    "        user_valid_hrate_df = user_valid_hrate_df.reset_index()\n",
    "        del user_valid_hrate_df['index'] \n",
    "        user_valid_hrate_df[\"hr\"] = wHr_lists\n",
    "        user_valid_hrate_dfs.append(user_valid_hrate_df)\n",
    "\n",
    "\n",
    "test_hrate_df[\"timestamp\"] = test_hrate_df[\"timestamp\"].astype(str)\n",
    "test_hrate_df[['date', 'timestamp']] = test_hrate_df['timestamp'].str.split(' ', expand=True)\n",
    "test_hrate_df = test_hrate_df[['subject_id', \"date\", \"timestamp\", \"heart_rate\"]]\n",
    "test_hrate_df.columns = ['userId', \"date\", \"timestamp\", \"hr\"]\n",
    "\n",
    "user_test_hrate_dfs = []\n",
    "test_sleep_users = sorted(list(set(list(test_hrate_df['userId']))))\n",
    "with tqdm.tqdm(test_sleep_users) as pbar:\n",
    "    pbar.set_description('Test Data')\n",
    "    for test_sleep_user in pbar:\n",
    "        user_test_hrate = test_hrate_df['userId'] == test_sleep_user   \n",
    "        user_test_hrate_df = test_hrate_df[user_test_hrate]\n",
    "        dates = sorted(list(user_test_hrate_df['date'].value_counts().keys()))\n",
    "\n",
    "        wHr_lists = []; remove_index = []\n",
    "        idx = -1\n",
    "        for date in dates:\n",
    "            idx += 1\n",
    "            user_split_test_hrate_df = user_test_hrate_df.loc[user_test_hrate_df.date == date]\n",
    "            wHr_date_list = list(user_split_test_hrate_df['hr'])\n",
    "            wHr_date_list = make_average_list(wHr_date_list, 50)\n",
    "            if len(wHr_date_list) == 0:\n",
    "                remove_index.append(idx)\n",
    "                pass\n",
    "            elif len(wHr_date_list) != 0:\n",
    "                wHr_lists.append(wHr_date_list)\n",
    "        \n",
    "        user_test_hrate_df = pd.DataFrame({\"userId\":test_sleep_user, \"date\":dates})\n",
    "        user_test_hrate_df = user_test_hrate_df.drop(index=remove_index)\n",
    "        user_test_hrate_df = user_test_hrate_df.reset_index()\n",
    "        del user_test_hrate_df['index']         \n",
    "        user_test_hrate_df[\"hr\"] = wHr_lists\n",
    "        user_test_hrate_dfs.append(user_test_hrate_df)\n",
    "\n",
    "print()\n",
    "\n",
    "user_valid_hrate_df = pd.concat(user_valid_hrate_dfs, axis=0).reset_index(drop=True)\n",
    "new_data = {'Q1': list(df_val_label['Q1']), 'Q2': list(df_val_label['Q2']), 'Q3': list(df_val_label['Q3']), \n",
    "            'S1': list(df_val_label['S1']), 'S2': list(df_val_label['S2']), 'S3': list(df_val_label['S3']), 'S4': list(df_val_label['S4'])}\n",
    "user_valid_hrate_df = user_valid_hrate_df.assign(**new_data)\n",
    "user_valid_hrate_df.to_csv(\"/workspace/data/valid_wHr_data.csv\", index=False)\n",
    "\n",
    "user_test_hrate_df = pd.concat(user_test_hrate_dfs, axis=0).reset_index(drop=True)\n",
    "new_data = {'Q1': list(df_test_label['Q1']), 'Q2': list(df_test_label['Q2']), 'Q3': list(df_test_label['Q3']), \n",
    "            'S1': list(df_test_label['S1']), 'S2': list(df_test_label['S2']), 'S3': list(df_test_label['S3']), 'S4': list(df_test_label['S4'])}\n",
    "user_test_hrate_df = user_test_hrate_df.assign(**new_data)\n",
    "user_test_hrate_df.to_csv(\"/workspace/data/test_wHr_data.csv\", index=False)\n",
    "\n",
    "print(colored(\"Valid wHr\", attrs=['bold']))\n",
    "pd.set_option('display.max_rows', 4)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "display(valid_hrate_df)\n",
    "print()\n",
    "\n",
    "print(colored(\"Test wHr\", attrs=['bold']))\n",
    "pd.set_option('display.max_rows', 4)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "display(test_hrate_df)\n",
    "print()\n",
    "\n",
    "print(colored(\"Valid wHr\", attrs=['bold']))\n",
    "pd.set_option('display.max_rows', 4)\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "display(user_valid_hrate_df)\n",
    "print()\n",
    "\n",
    "print(colored(\"Test wHr\", attrs=['bold']))\n",
    "pd.set_option('display.max_rows', 4)\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "display(user_test_hrate_df)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.0 mGps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "스마트폰에서 산출된 GPS 좌표 정보(단, 위도 및 경도는 상대 좌표로 변환됨). 5초 간격(1분당 약 12회)으로 측정됨."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_average_list(data, length): \n",
    "    average_list = []\n",
    "    for i in range(0, len(data), length): \n",
    "        nested_list = data[i:i + length]\n",
    "        netsed_mean = np.mean(nested_list)\n",
    "        average_list.append(netsed_mean)\n",
    "    return average_list\n",
    "\n",
    "val_dataset_path = \"workspace/human_understanding_2024/val_dataset\"\n",
    "test_dataset_path = \"workspace/human_understanding_2024/test_dataset\"\n",
    "\n",
    "valid_file_name = \"ch2024_val__m_gps.parquet.gzip\"\n",
    "test_file_name = \"ch2024_test_m_gps.parquet.gzip\"\n",
    "\n",
    "val_label_path = \"workspace/human_understanding_2024/val_label.csv\"\n",
    "test_label_path = \"workspace/human_understanding_2024/answer_sample.csv\"\n",
    "\n",
    "df_val_label = pd.read_csv(val_label_path)\n",
    "df_test_label = pd.read_csv(test_label_path)\n",
    "\n",
    "valid_mGps_df = pd.read_parquet(os.path.join(val_dataset_path, valid_file_name))\n",
    "test_mGps_df  = pd.read_parquet(os.path.join(test_dataset_path, test_file_name))\n",
    "\n",
    "valid_mGps_df = valid_mGps_df[(valid_mGps_df['latitude'] != 0) & (valid_mGps_df['longitude'] != 0)]\n",
    "test_mGps_df = test_mGps_df[(test_mGps_df['latitude'] != 0) & (test_mGps_df['longitude'] != 0)]\n",
    "\n",
    "valid_mGps_df[\"timestamp\"] = valid_mGps_df[\"timestamp\"].astype(str)\n",
    "valid_mGps_df[['date', 'timestamp']] = valid_mGps_df['timestamp'].str.split(' ', expand=True)\n",
    "valid_mGps_df = valid_mGps_df[['subject_id', \"date\", \"timestamp\", \"latitude\", \"longitude\"]]\n",
    "valid_mGps_df.columns = ['userId', \"date\", \"timestamp\", \"lat\", \"lon\"]\n",
    "\n",
    "test_mGps_df[\"timestamp\"] = test_mGps_df[\"timestamp\"].astype(str)\n",
    "test_mGps_df[['date', 'timestamp']] = test_mGps_df['timestamp'].str.split(' ', expand=True)\n",
    "test_mGps_df = test_mGps_df[['subject_id', \"date\", \"timestamp\", \"latitude\", \"longitude\"]]\n",
    "test_mGps_df.columns = ['userId', \"date\", \"timestamp\", \"lat\", \"lon\"]\n",
    "\n",
    "user_valid_mGps_dfs = []\n",
    "valid_sleep_users = sorted(list(set(list(valid_mGps_df['userId']))))\n",
    "with tqdm.tqdm(valid_sleep_users) as pbar:\n",
    "    pbar.set_description('Validation Data')\n",
    "    for valid_sleep_user in pbar:\n",
    "        user_valid_mGps = valid_mGps_df['userId'] == valid_sleep_user   \n",
    "        user_valid_mGps_df = valid_mGps_df[user_valid_mGps]\n",
    "        user_valid_mGps_df = user_valid_mGps_df.sort_values(\"date\").reset_index(drop=True)\n",
    "        \n",
    "        dates = sorted(list(user_valid_mGps_df['date'].value_counts().keys()))\n",
    "\n",
    "        lat_lists = []; lon_lists = []; remove_index = []\n",
    "        idx = -1\n",
    "        for date in dates:\n",
    "            idx += 1\n",
    "            user_split_valid_mGps_df = user_valid_mGps_df.loc[user_valid_mGps_df.date == date]\n",
    "            lat_date_list = list(user_split_valid_mGps_df['lat'])\n",
    "            lat_date_list = make_average_list(lat_date_list, 50)\n",
    "\n",
    "            lon_date_list = list(user_split_valid_mGps_df['lon'])\n",
    "            lon_date_list = make_average_list(lon_date_list, 50)\n",
    "\n",
    "            if len(lat_date_list) == 0 or len(lon_date_list) == 0:\n",
    "                remove_index.append(idx)\n",
    "                pass\n",
    "            else:\n",
    "                lat_lists.append(lat_date_list)\n",
    "                lon_lists.append(lon_date_list)\n",
    "\n",
    "        user_valid_mGps_df = pd.DataFrame({\"userId\":valid_sleep_user, \"date\":dates})\n",
    "        user_valid_mGps_df = user_valid_mGps_df.drop(index=remove_index)\n",
    "        user_valid_mGps_df = user_valid_mGps_df.reset_index()\n",
    "        del user_valid_mGps_df['index']  \n",
    "        user_valid_mGps_df[\"lat\"] = lat_lists\n",
    "        user_valid_mGps_df[\"lon\"] = lon_lists\n",
    "        user_valid_mGps_dfs.append(user_valid_mGps_df)\n",
    "\n",
    "user_test_mGps_dfs = []\n",
    "test_sleep_users = sorted(list(set(list(test_mGps_df['userId']))))\n",
    "with tqdm.tqdm(test_sleep_users) as pbar:\n",
    "    pbar.set_description('Test Data')\n",
    "    for test_sleep_user in pbar:\n",
    "        user_test_mGps = test_mGps_df['userId'] == test_sleep_user   \n",
    "        user_test_mGps_df = test_mGps_df[user_test_mGps]\n",
    "        user_test_mGps_df = user_test_mGps_df.sort_values(\"date\").reset_index(drop=True)\n",
    "\n",
    "        dates = sorted(list(user_test_mGps_df['date'].value_counts().keys()))\n",
    "\n",
    "        lat_lists = []; lon_lists = []; remove_index = []\n",
    "        idx = -1\n",
    "        for date in dates:\n",
    "            idx += 1\n",
    "            user_split_test_mGps_df = user_test_mGps_df.loc[user_test_mGps_df.date == date]\n",
    "            lat_date_list = list(user_split_test_mGps_df['lat'])\n",
    "            lat_date_list = make_average_list(lat_date_list, 50)\n",
    "\n",
    "            lon_date_list = list(user_split_test_mGps_df['lon'])\n",
    "            lon_date_list = make_average_list(lon_date_list, 50)\n",
    "\n",
    "            if len(lat_date_list) == 0 or len(lon_date_list) == 0:\n",
    "                remove_index.append(idx)\n",
    "                pass\n",
    "            else:\n",
    "                lat_lists.append(lat_date_list)\n",
    "                lon_lists.append(lon_date_list)\n",
    "\n",
    "        user_test_mGps_df = pd.DataFrame({\"userId\":test_sleep_user, \"date\":dates})\n",
    "        user_test_mGps_df = user_test_mGps_df.drop(index=remove_index)\n",
    "        user_test_mGps_df = user_test_mGps_df.reset_index()\n",
    "        del user_test_mGps_df['index']  \n",
    "        user_test_mGps_df[\"lat\"] = lat_lists\n",
    "        user_test_mGps_df[\"lon\"] = lon_lists\n",
    "        user_test_mGps_dfs.append(user_test_mGps_df)\n",
    "\n",
    "print()\n",
    "\n",
    "user_valid_mGps_df = pd.concat(user_valid_mGps_dfs, axis=0).reset_index(drop=True)\n",
    "data_names = []; text_names = []\n",
    "for i, j, k, l in zip(user_valid_mGps_df['userId'], user_valid_mGps_df['date'], df_val_label['subject_id'], df_val_label['date']):\n",
    "    data_name = str(i) + \" \" + str(j); data_names.append(data_name)\n",
    "    text_name = str(k) + \" \" + str(l); text_names.append(text_name)\n",
    "\n",
    "for text_name in text_names:\n",
    "    try: \n",
    "        data_names.index(text_name)\n",
    "    except:\n",
    "        remove_index = df_val_label[(df_val_label.subject_id.astype(str) == text_name.split(\" \")[0]) & (df_val_label.date.astype(str) == text_name.split(\" \")[1])].index[0]\n",
    "        df_val_label = df_val_label.drop(remove_index)\n",
    "\n",
    "user_test_mGps_df = pd.concat(user_test_mGps_dfs, axis=0).reset_index(drop=True)\n",
    "data_names = []; text_names = []\n",
    "for i, j, k, l in zip(user_test_mGps_df['userId'], user_test_mGps_df['date'], df_test_label['subject_id'], df_test_label['date']):\n",
    "    data_name = str(i) + \" \" + str(j); data_names.append(data_name)\n",
    "    text_name = str(k) + \" \" + str(l); text_names.append(text_name)\n",
    "\n",
    "for text_name in text_names:\n",
    "    try: \n",
    "        data_names.index(text_name)\n",
    "    except:\n",
    "        remove_index = df_test_label[(df_test_label.subject_id.astype(str) == text_name.split(\" \")[0]) & (df_test_label.date.astype(str) == text_name.split(\" \")[1])].index[0]\n",
    "        df_test_label = df_test_label.drop(remove_index)\n",
    "\n",
    "new_data = {'Q1': list(df_val_label['Q1']), 'Q2': list(df_val_label['Q2']), 'Q3': list(df_val_label['Q3']), \n",
    "            'S1': list(df_val_label['S1']), 'S2': list(df_val_label['S2']), 'S3': list(df_val_label['S3']), 'S4': list(df_val_label['S4'])}\n",
    "user_valid_mGps_df = user_valid_mGps_df.assign(**new_data)\n",
    "user_valid_mGps_df.to_csv(\"/workspace/data/valid_mGps_data.csv\", index=False)\n",
    "\n",
    "user_test_mGps_df = pd.concat(user_test_mGps_dfs, axis=0).reset_index(drop=True)\n",
    "new_data = {'Q1': list(df_test_label['Q1']), 'Q2': list(df_test_label['Q2']), 'Q3': list(df_test_label['Q3']), \n",
    "            'S1': list(df_test_label['S1']), 'S2': list(df_test_label['S2']), 'S3': list(df_test_label['S3']), 'S4': list(df_test_label['S4'])}\n",
    "user_test_mGps_df = user_test_mGps_df.assign(**new_data)\n",
    "user_test_mGps_df.to_csv(\"/workspace/data/test_mGps_data.csv\", index=False)\n",
    "\n",
    "print(colored(\"Valid mGps\", attrs=['bold']))\n",
    "pd.set_option('display.max_rows', 4)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "display(valid_mGps_df)\n",
    "print()\n",
    "\n",
    "print(colored(\"Test mGps\", attrs=['bold']))\n",
    "pd.set_option('display.max_rows', 4)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "display(test_mGps_df)\n",
    "print()\n",
    "\n",
    "print(colored(\"Valid mGps\", attrs=['bold']))\n",
    "pd.set_option('display.max_rows', 4)\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "display(user_valid_mGps_df)\n",
    "print()\n",
    "\n",
    "print(colored(\"Test mGps\", attrs=['bold']))\n",
    "pd.set_option('display.max_rows', 4)\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "display(user_test_mGps_df)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4.0 mAcc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "스마트폰의 가속도 센서 데이터. 1초당 약 50회씩(50Hz) 측정됨."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_average_list(data, length): \n",
    "    average_list = []\n",
    "    for i in range(0, len(data), length): \n",
    "        nested_list = data[i:i + length]\n",
    "        netsed_mean = np.mean(nested_list)\n",
    "        average_list.append(netsed_mean)\n",
    "    return average_list\n",
    "\n",
    "def divide_date_df(l): \n",
    "    nested_df = []; nested_lens = []\n",
    "    userids = sorted(list(set(list(l['subject_id']))))\n",
    "    for userid in userids:\n",
    "        userid_label = l['subject_id'] == userid   \n",
    "        userid_label_df = l[userid_label]\n",
    "        userid_label_df = userid_label_df.reset_index()\n",
    "        del userid_label_df['index']\n",
    "        nested_len = len(userid_label_df)\n",
    "        nested_df.append(userid_label_df)\n",
    "        nested_lens.append(nested_len)\n",
    "    return nested_df, nested_lens\n",
    "\n",
    "valid_mAcc_dfs = []; test_mAcc_dfs =[]\n",
    "\n",
    "val_dataset_path = \"workspace/human_understanding_2024/val_dataset\"\n",
    "test_dataset_path = \"workspace/human_understanding_2024/test_dataset\"\n",
    "\n",
    "valid_file_names = [\"ch2024_val__m_acc_part_1.parquet.gzip\",\n",
    "              \"ch2024_val__m_acc_part_2.parquet.gzip\",\n",
    "              \"ch2024_val__m_acc_part_3.parquet.gzip\",\n",
    "              \"ch2024_val__m_acc_part_4.parquet.gzip\"]\n",
    "test_file_names = [\"ch2024_test__m_acc_part_5.parquet.gzip\",\n",
    "              \"ch2024_test__m_acc_part_6.parquet.gzip\",\n",
    "              \"ch2024_test__m_acc_part_7.parquet.gzip\",\n",
    "              \"ch2024_test__m_acc_part_8.parquet.gzip\"]\n",
    "\n",
    "val_label_path = \"workspace/human_understanding_2024/val_label.csv\"\n",
    "test_label_path = \"workspace/human_understanding_2024/answer_sample.csv\"\n",
    "\n",
    "df_val_label = pd.read_csv(val_label_path)\n",
    "df_test_label = pd.read_csv(test_label_path)\n",
    "\n",
    "df_val_labels, nested_val_lens  = divide_date_df(df_val_label)\n",
    "df_test_labels, nested_test_lens  = divide_date_df(df_test_label)\n",
    "\n",
    "df_val_label\n",
    "valid_idx = 0; test_idx = 0\n",
    "for valid_file_name, test_file_name, df_val_label, df_test_label in zip(valid_file_names, test_file_names, df_val_labels, df_test_labels):\n",
    "    valid_mAcc_df = pd.read_parquet(os.path.join(val_dataset_path, valid_file_name)) \n",
    "    test_mAcc_df = pd.read_parquet(os.path.join(test_dataset_path, test_file_name)) \n",
    "\n",
    "    user_valid_mAcc_df = valid_mAcc_df.copy()\n",
    "    user_test_mAcc_df = test_mAcc_df.copy()\n",
    "\n",
    "    valid_mAcc_df = valid_mAcc_df[(valid_mAcc_df['x'] != 0) & (valid_mAcc_df['y'] != 0) & (valid_mAcc_df['z'] != 0)]\n",
    "    test_mAcc_df = test_mAcc_df[(test_mAcc_df['x'] != 0) & (test_mAcc_df['y'] != 0) & (test_mAcc_df['z'] != 0)]\n",
    "\n",
    "    valid_mAcc_df = valid_mAcc_df.copy()\n",
    "    valid_mAcc_df['timestamp'] = pd.to_datetime(valid_mAcc_df['timestamp'], format='%Y-%m-%d %H:%M:%S.%f').dt.date\n",
    "    valid_mAcc_df.columns = ['userId', \"date\", \"x\", \"y\", \"z\"] \n",
    "\n",
    "    test_mAcc_df = test_mAcc_df.copy()\n",
    "    test_mAcc_df['timestamp'] = pd.to_datetime(test_mAcc_df['timestamp'], format='%Y-%m-%d %H:%M:%S.%f').dt.date\n",
    "    test_mAcc_df.columns = ['userId', \"date\", \"x\", \"y\", \"z\"] \n",
    "\n",
    "    valid_mAcc_len = [i for i in range(len(valid_mAcc_dfs))]\n",
    "    test_mAcc_len = [i for i in range(len(test_mAcc_dfs))]\n",
    "\n",
    "    valid_idx += 1\n",
    "    dates = sorted(list(valid_mAcc_df['date'].value_counts().keys()))\n",
    "\n",
    "    x_lists = []; y_lists = []; z_lists = []; remove_index = []\n",
    "    idx = -1\n",
    "    with tqdm.tqdm(dates) as pbar:\n",
    "        pbar.set_description(f\"Valid {valid_idx}/{len(valid_file_names)}\")\n",
    "        for date in pbar:\n",
    "            idx += 1\n",
    "            user_split_valid_mAcc_df = valid_mAcc_df.loc[valid_mAcc_df.date == date]\n",
    "            x_date_list = list(user_split_valid_mAcc_df['x'])\n",
    "            y_date_list = list(user_split_valid_mAcc_df['y'])\n",
    "            z_date_list = list(user_split_valid_mAcc_df['z'])\n",
    "            x_date_list = make_average_list(x_date_list, 50)\n",
    "            y_date_list = make_average_list(y_date_list, 50)\n",
    "            z_date_list = make_average_list(z_date_list, 50)\n",
    "\n",
    "            if len(x_date_list) == 0 or len(y_date_list) == 0 or len(z_date_list) == 0:\n",
    "                remove_index.append(idx)\n",
    "                pass\n",
    "            else:\n",
    "                x_lists.append(x_date_list)\n",
    "                y_lists.append(y_date_list)\n",
    "                z_lists.append(z_date_list)\n",
    "\n",
    "    valid_sleep_user = [list(valid_mAcc_df[\"userId\"])[0]] * len(dates)\n",
    "    valid_mAcc_df = pd.DataFrame({\"userId\":valid_sleep_user, \"date\":dates})\n",
    "    valid_mAcc_df = valid_mAcc_df.reset_index()\n",
    "    del valid_mAcc_df['index']  \n",
    "    valid_mAcc_df = valid_mAcc_df.drop(index=remove_index)\n",
    "    valid_mAcc_df[\"x\"] = x_lists\n",
    "    valid_mAcc_df[\"y\"] = y_lists\n",
    "    valid_mAcc_df[\"z\"] = z_lists\n",
    "\n",
    "    data_names = []; text_names = []\n",
    "    for i, j, k, l in zip(valid_mAcc_df['userId'], valid_mAcc_df['date'], df_val_label['subject_id'], df_val_label['date']):\n",
    "        data_name = str(i) + \" \" + str(j); data_names.append(data_name)\n",
    "        text_name = str(k) + \" \" + str(l); text_names.append(text_name)\n",
    "\n",
    "    for text_name in text_names:\n",
    "        try: \n",
    "            data_names.index(text_name)\n",
    "        except:\n",
    "            remove_index = df_val_label[(df_val_label.subject_id.astype(str) == text_name.split(\" \")[0]) & (df_val_label.date.astype(str) == text_name.split(\" \")[1])].index[0]\n",
    "            df_val_label = df_val_label.drop(remove_index)\n",
    "\n",
    "    new_data = {'Q1': list(df_val_label['Q1']), 'Q2': list(df_val_label['Q2']), 'Q3': list(df_val_label['Q3']), \n",
    "                'S1': list(df_val_label['S1']), 'S2': list(df_val_label['S2']), 'S3': list(df_val_label['S3']), 'S4': list(df_val_label['S4'])}\n",
    "    valid_mAcc_df = valid_mAcc_df.assign(**new_data)\n",
    " \n",
    "    if valid_idx < 9: str_valid_idx = \"0\" + str(valid_idx)\n",
    "    elif valid_idx >= 9: str_valid_idx = str(valid_idx)\n",
    "\n",
    "    valid_mAcc_df.to_csv(\"/workspace/data/valid_mAcc_data_\" + str_valid_idx + \".csv\", index=False)\n",
    "\n",
    "    test_idx += 1\n",
    "    dates = sorted(list(test_mAcc_df['date'].value_counts().keys()))\n",
    "\n",
    "    x_lists = []; y_lists = []; z_lists = []; remove_index = []\n",
    "    idx = -1\n",
    "    with tqdm.tqdm(dates) as pbar:\n",
    "        pbar.set_description(f\"Test {test_idx}/{len(test_file_names)}\")\n",
    "        for date in pbar:\n",
    "            idx += 1\n",
    "            user_split_test_mAcc_df = test_mAcc_df.loc[test_mAcc_df.date == date]\n",
    "            x_date_list = list(user_split_test_mAcc_df['x'])\n",
    "            y_date_list = list(user_split_test_mAcc_df['y'])\n",
    "            z_date_list = list(user_split_test_mAcc_df['z'])\n",
    "            x_date_list = make_average_list(x_date_list, 50)\n",
    "            y_date_list = make_average_list(y_date_list, 50)\n",
    "            z_date_list = make_average_list(z_date_list, 50)\n",
    "\n",
    "            if len(x_date_list) == 0 or len(y_date_list) == 0 or len(z_date_list) == 0:\n",
    "                remove_index.append(idx)\n",
    "                pass\n",
    "            else:\n",
    "                x_lists.append(x_date_list)\n",
    "                y_lists.append(y_date_list)\n",
    "                z_lists.append(z_date_list)\n",
    "\n",
    "    test_sleep_user = [list(test_mAcc_df[\"userId\"])[0]] * len(dates)\n",
    "    test_mAcc_df = pd.DataFrame({\"userId\":test_sleep_user, \"date\":dates})\n",
    "    test_mAcc_df = test_mAcc_df.drop(index=remove_index)\n",
    "    test_mAcc_df = test_mAcc_df.reset_index()\n",
    "    del test_mAcc_df['index']      \n",
    "    test_mAcc_df[\"x\"] = x_lists\n",
    "    test_mAcc_df[\"y\"] = y_lists\n",
    "    test_mAcc_df[\"z\"] = z_lists\n",
    "\n",
    "    data_names = []; text_names = []\n",
    "    for i, j, k, l in zip(test_mAcc_df['userId'], test_mAcc_df['date'], df_test_label['subject_id'], df_test_label['date']):\n",
    "        data_name = str(i) + \" \" + str(j); data_names.append(data_name)\n",
    "        text_name = str(k) + \" \" + str(l); text_names.append(text_name)\n",
    "\n",
    "    for text_name in text_names:\n",
    "        try: \n",
    "            data_names.index(text_name)\n",
    "        except:\n",
    "            remove_index = df_test_label[(df_test_label.subject_id.astype(str) == text_name.split(\" \")[0]) & (df_test_label.date.astype(str) == text_name.split(\" \")[1])].index[0]\n",
    "            df_test_label = df_test_label.drop(remove_index)\n",
    "\n",
    "    new_data = {'Q1': list(df_test_label['Q1']), 'Q2': list(df_test_label['Q2']), 'Q3': list(df_test_label['Q3']), \n",
    "                'S1': list(df_test_label['S1']), 'S2': list(df_test_label['S2']), 'S3': list(df_test_label['S3']), 'S4': list(df_test_label['S4'])}\n",
    "    test_mAcc_df = test_mAcc_df.assign(**new_data)\n",
    "\n",
    "    if test_idx < 9: str_test_idx = \"0\" + str(test_idx)\n",
    "    elif test_idx >= 9: str_test_idx = str(test_idx)\n",
    "\n",
    "    test_mAcc_df.to_csv(\"/workspace/data/test_mAcc_data_\" + str_test_idx + \".csv\", index=False)\n",
    "\n",
    "print(colored(\"Valid mAcc\", attrs=['bold']))\n",
    "pd.set_option('display.max_rows', 4)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "display(user_valid_mAcc_df)\n",
    "print()\n",
    "\n",
    "print(colored(\"Test mAcc\", attrs=['bold']))\n",
    "pd.set_option('display.max_rows', 4)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "display(user_test_mAcc_df)\n",
    "print()\n",
    "\n",
    "print(colored(\"Valid mAcc\", attrs=['bold']))\n",
    "pd.set_option('display.max_rows', 4)\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "display(valid_mAcc_df)\n",
    "print()\n",
    "\n",
    "print(colored(\"Test mAcc\", attrs=['bold']))\n",
    "pd.set_option('display.max_rows', 4)\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "display(test_mAcc_df)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>AIFactory Competition</b>\n",
    "<br>[제3회 ETRI 휴먼이해 인공지능 논문경진대회](https://aifactory.space/task/2790/overview)\n",
    "\n",
    "<b>ETRI</b>\n",
    "<br>[ETRI Lifelog Dataset 2020 (English)](https://nanum.etri.re.kr/share/schung1/ETRILifelogDataset2020?lang=ko_KR)\n",
    "<br>[ETRI Lifelog Dataset 2020 (Korean)](https://nanum.etri.re.kr/share/schung1/ETRILifelogDataset2020?lang=ko_KR)\n",
    "\n",
    "<br><b>Paper</b>\n",
    "<br>[Human Understanding AI Paper Challenge 2024 - Dataset Design](https://arxiv.org/abs/2403.16509)\n",
    "<br>[라이프로그 기반 일상생활 활동유형에 대한 탐색적 연구]()\n",
    "<br>[Real-world multimodal lifelog dataset for human behavior study](https://kiss.kstudy.com/Detail/Ar?key=3860737)\n",
    "<br>[An empirical study on finding experience sampling\n",
    "parameters to explain sleep quality based on\n",
    "dimension reduction](https://www.researchgate.net/publication/338365671_An_empirical_study_on_finding_experience_sampling_parameters_to_explain_sleep_quality_based_on_dimension_reduction)\n",
    "<br>[Assessing Sleep Quality Using Mobile EMAs: Opportunities, Practical Consideration, and Challenges](https://ieeexplore.ieee.org/document/9667514)\n",
    "<br>[Finding Points-of-Interest (PoIs) from Life-logging and Location Trace Data](https://ieeexplore.ieee.org/document/8940021)\n",
    "<br>[Sensor Data Acquisition and Multimodal Sensor Fusion for Human Activity Recognition Using Deep Learning](https://www.mdpi.com/1424-8220/19/7/1716)\n",
    "<br>[SPER: Stay-Point Extraction considering Revisits in a Single Trajectory](https://ieeexplore.ieee.org/document/9621139)\n",
    "<br>[Population Based Training of Neural Networks](https://arxiv.org/abs/1711.09846)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.1.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
