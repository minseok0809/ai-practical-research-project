{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ltexo_m-Iym2"
      },
      "outputs": [],
      "source": [
        "!pip install gdown"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "id": "GJeYsc6CS5Ag"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_id = \"18yNkW3GVzwzp6M9pJcilPXqLNZ4PxEen\"\n",
        "url = f\"https://drive.google.com/uc?id={file_id}\""
      ],
      "metadata": {
        "id": "VJRXz1xzI8qI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "before_files = set(os.listdir())\n",
        "\n",
        "!gdown {url}\n",
        "\n",
        "after_files = set(os.listdir())\n",
        "\n",
        "downloaded_files = after_files - before_files\n",
        "if downloaded_files:\n",
        "    filename = downloaded_files.pop()\n",
        "    print(f\"Downloaded file: {filename}\")\n",
        "    downloaded_filepath = filename\n",
        "else:\n",
        "    print(\"No file downloaded.\")"
      ],
      "metadata": {
        "id": "kWXXlaeIJSEZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e730491d-6bdf-4a51-f9e3-f57d044a83b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=18yNkW3GVzwzp6M9pJcilPXqLNZ4PxEen\n",
            "To: /content/clickbait_detection.zip\n",
            "100% 650M/650M [00:09<00:00, 65.1MB/s]\n",
            "Downloaded file: clickbait_detection.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip {downloaded_filepath}"
      ],
      "metadata": {
        "id": "Q53xaLnYJU3U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f0cdfb91-e83a-49b2-d0c1-6bbb69404016"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  clickbait_detection.zip\n",
            "   creating: clickbait_detection/\n",
            "  inflating: clickbait_detection/config.yaml  \n",
            "   creating: clickbait_detection/data/\n",
            "  inflating: clickbait_detection/data/test_dataset.csv  \n",
            "  inflating: clickbait_detection/data/train_dataset.csv  \n",
            "  inflating: clickbait_detection/data/valid_dataset.csv  \n",
            "  inflating: clickbait_detection/flow_validation.py  \n",
            "  inflating: clickbait_detection/model_inference.py  \n",
            "  inflating: clickbait_detection/random_inference.py  \n",
            "  inflating: clickbait_detection/score.py  \n",
            "  inflating: clickbait_detection/train.py  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd clickbait_detection"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3EvOEbdFSkgB",
        "outputId": "b6e43ea6-2d97-4b1e-f8cc-6f2393a1a241"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/clickbait_detection\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python flow_validation.py"
      ],
      "metadata": {
        "id": "tSpK1yIHJWRp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15d24f12-bce2-431c-aa21-c5d9dcace64f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files cleanup completed.\n",
            "Start 'python random_inference.py data/test_dataset.csv y_test.csv y_rand_pred.csv'\n",
            "Done 0.86 seconds\n",
            "Start 'python score.py y_test.csv y_rand_pred.csv random_score.txt'\n",
            "Done 0.53 seconds\n",
            "Start 'python train.py data/train_dataset.csv model.bin'\n",
            "Downloading (…)lve/main/config.json: 100% 545/545 [00:00<00:00, 2.67MB/s]\n",
            "Downloading model.safetensors: 100% 273M/273M [00:10<00:00, 27.0MB/s]\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at klue/roberta-small and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Downloading (…)okenizer_config.json: 100% 375/375 [00:00<00:00, 1.86MB/s]\n",
            "Downloading (…)solve/main/vocab.txt: 100% 248k/248k [00:00<00:00, 3.17MB/s]\n",
            "Downloading (…)/main/tokenizer.json: 100% 752k/752k [00:00<00:00, 14.7MB/s]\n",
            "Downloading (…)cial_tokens_map.json: 100% 173/173 [00:00<00:00, 868kB/s]\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "Epoch 1:   0% 0/63 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2622: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "Epoch 1:   2% 1/63 [00:04<04:59,  4.83s/it]/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2622: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "Epoch 1: 100% 63/63 [01:33<00:00,  1.48s/it]\n",
            "Train Time 00:01:33    Train Loss: 43.6873    Train Accuracy: 0.5106\n",
            "Epoch 2: 100% 63/63 [01:35<00:00,  1.51s/it]\n",
            "Train Time 00:01:35    Train Loss: 42.7514    Train Accuracy: 0.5741\n",
            "Epoch 3: 100% 63/63 [01:39<00:00,  1.57s/it]\n",
            "Train Time 00:01:39    Train Loss: 41.2262    Train Accuracy: 0.6068\n",
            "Epoch 4: 100% 63/63 [01:39<00:00,  1.58s/it]\n",
            "Train Time 00:01:39    Train Loss: 37.9826    Train Accuracy: 0.6673\n",
            "Epoch 5: 100% 63/63 [01:39<00:00,  1.58s/it]\n",
            "Train Time 00:01:39    Train Loss: 32.2013    Train Accuracy: 0.7491\n",
            "Done 547.85 seconds\n",
            "Start 'python model_inference.py model.bin data/test_dataset.csv y_pred.csv'\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at klue/roberta-small and are newly initialized: ['classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Epoch 1:   0% 0/8 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2622: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "Epoch 1:  12% 1/8 [00:01<00:09,  1.35s/it]/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2622: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "Epoch 1: 100% 8/8 [00:05<00:00,  1.48it/s]\n",
            "Test Time 00:00:05    Test Accuracy: 0.5768\n",
            "Done 14.51 seconds\n",
            "Start 'python score.py y_test.csv y_pred.csv model_score.txt'\n",
            "Done 0.53 seconds\n",
            "y_rand_pred_filepath check passed! (+10 points)\n",
            "random_score_filepath check passed! (+10 points)\n",
            "model_filepath check passed! (+10 points)\n",
            "y_pred_filepath check passed! (+10 points)\n",
            "model_score_filepath check passed! (+10 points)\n",
            "score_validation check passed! (+10 points)\n",
            "Total score: 100 / 100\n"
          ]
        }
      ]
    }
  ]
}